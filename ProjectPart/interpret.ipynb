{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Imports"
      ],
      "metadata": {
        "id": "-7h7ICuuoRi8"
      },
      "id": "-7h7ICuuoRi8"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def find_path(name, path='/content'):\n",
        "    '''\n",
        "    поиск файла или папки\n",
        "    '''\n",
        "    result = []\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        if name in files+dirs:\n",
        "          result.append([os.path.join(root, name), root])\n",
        "    return result\n",
        "\n",
        "if len(find_path('MyDrive')) == 0 and True:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "if True:\n",
        "  os.chdir(find_path('full_train.ipynb')[0][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbkf3tRCln2B",
        "outputId": "3c1cb7b5-9cdc-4ad4-9d06-c7ca8bb095d2"
      },
      "id": "fbkf3tRCln2B",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install --upgrade git+https://github.com/evfro/polara.git@develop#egg=polara\n",
        "#! wget -q https://raw.githubusercontent.com/Personalization-Technologies-Lab/RecSys-Course-HSE-Fall23/main/Seminar5/dataprep.py -O dataprep.py\n",
        "#! wget -q https://raw.githubusercontent.com/Personalization-Technologies-Lab/RecSys-Course-HSE-Fall23/main/Seminar5/evaluation.py -O evaluation.py\n",
        "!pip -q install ray==2.9.0\n",
        "!pip -q install Bottleneck==1.3.7\n",
        "!pip -q install optuna==3.5.0\n",
        "!pip -q install omegaconf==2.3.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3NVwhO3l5hZ",
        "outputId": "0d7589ac-3868-40a8-81e5-2fa3646ca517"
      },
      "id": "r3NVwhO3l5hZ",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for polara (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.0/354.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.4/413.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "d09203eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d09203eb",
        "outputId": "bfaedb19-b9bc-41dd-b71e-a34383e40542"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import sys\n",
        "from pathlib import Path\n",
        "protomf_path = Path(\"./ProtoMF/\")\n",
        "sys.path.append(protomf_path.__str__())\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "from confs.hyper_params import mf_hyper_params, anchor_hyper_params, user_proto_chose_original_hyper_params, \\\n",
        "    item_proto_chose_original_hyper_params, proto_double_tie_chose_original_hyper_params\n",
        "from experiment_helper import start_hyper, start_multiple_hyper\n",
        "from utilities.consts import SINGLE_SEED\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "b02a2629",
      "metadata": {
        "id": "b02a2629"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from ray import tune\n",
        "from torch import nn\n",
        "from torch.utils import data\n",
        "from feature_extraction.feature_extractor_factories import FeatureExtractorFactory\n",
        "from rec_sys_folder.rec_sys import RecSys\n",
        "from utilities.consts import OPTIMIZING_METRIC, MAX_PATIENCE\n",
        "from utilities.eval import Evaluator\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import sparse as sp\n",
        "from torch.utils import data\n",
        "from torch.utils.data.dataset import T_co\n",
        "from functools import partial\n",
        "import torch\n",
        "from torch import nn\n",
        "from feature_extraction.feature_extractors import FeatureExtractor\n",
        "import argparse\n",
        "from ray import tune\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "from ray.tune.search.hyperopt import HyperOptSearch\n",
        "from rec_sys_folder.protomf_dataset import get_protorecdataset_dataloader\n",
        "from rec_sys_folder.tester import Tester\n",
        "from rec_sys_folder.trainer import Trainer\n",
        "from utilities.consts import NEG_VAL, OPTIMIZING_METRIC, SEED_LIST, SINGLE_SEED, NUM_SAMPLES, \\\n",
        "    PROJECT_NAME, DATA_PATH, NUM_WORKERS, CPU_PER_TRIAL, GPU_PER_TRIAL, WANDB_API_KEY\n",
        "from ray.air.integrations.wandb import WandbLoggerCallback\n",
        "from utilities.utils import reproducible, generate_id\n",
        "import platform"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Functions (not see)"
      ],
      "metadata": {
        "id": "ZZtpylKjoW1c"
      },
      "id": "ZZtpylKjoW1c"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b7c4d057",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7c4d057",
        "outputId": "09f18516-9fda-46b5-976e-ca773b294997"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3c0ff974",
      "metadata": {
        "id": "3c0ff974"
      },
      "outputs": [],
      "source": [
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "aba4b22e",
      "metadata": {
        "id": "aba4b22e"
      },
      "outputs": [],
      "source": [
        "def load_data(conf: argparse.Namespace, is_train: bool = True):\n",
        "    if is_train:\n",
        "        train_loader = get_protorecdataset_dataloader(\n",
        "            data_path=conf.data_path,\n",
        "            split_set='train',\n",
        "            n_neg=conf.neg_train,\n",
        "            neg_strategy=conf.train_neg_strategy,\n",
        "            batch_size=conf.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=NUM_WORKERS,\n",
        "            prefetch_factor=5\n",
        "        )\n",
        "\n",
        "        val_loader = get_protorecdataset_dataloader(\n",
        "            data_path=conf.data_path,\n",
        "            split_set='val',\n",
        "            n_neg=NEG_VAL,\n",
        "            neg_strategy=conf.eval_neg_strategy,\n",
        "            batch_size=conf.val_batch_size,\n",
        "            num_workers=NUM_WORKERS\n",
        "        )\n",
        "\n",
        "        test_loader = get_protorecdataset_dataloader(\n",
        "            data_path=conf.data_path,\n",
        "            split_set='test',\n",
        "            n_neg=NEG_VAL,\n",
        "            neg_strategy=conf.eval_neg_strategy,\n",
        "            batch_size=conf.val_batch_size,\n",
        "            num_workers=NUM_WORKERS\n",
        "        )\n",
        "\n",
        "        return {'train_loader': train_loader, 'val_loader': val_loader, 'test_loader': test_loader}\n",
        "    else:\n",
        "\n",
        "        test_loader = get_protorecdataset_dataloader(\n",
        "            data_path=conf.data_path,\n",
        "            split_set='test',\n",
        "            n_neg=NEG_VAL,\n",
        "            neg_strategy=conf.eval_neg_strategy,\n",
        "            batch_size=conf.val_batch_size,\n",
        "            num_workers=NUM_WORKERS\n",
        "        )\n",
        "\n",
        "        return {'test_loader': test_loader}\n",
        "\n",
        "\n",
        "def start_training(config):\n",
        "    config = argparse.Namespace(**config)\n",
        "    print(config)\n",
        "\n",
        "    data_loaders_dict = load_data(config)\n",
        "\n",
        "    reproducible(config.seed)\n",
        "\n",
        "    # trainer = Trainer(data_loaders_dict['train_loader'], data_loaders_dict['val_loader'], data_loaders_dict['test_loader'], config)\n",
        "    trainer = Trainer(data_loaders_dict['train_loader'], data_loaders_dict['val_loader'],  config)\n",
        "\n",
        "\n",
        "    trainer.run()\n",
        "\n",
        "    wandb.finish()\n",
        "\n",
        "\n",
        "def start_testing(config, model_load_path: str):\n",
        "    config = argparse.Namespace(**config)\n",
        "    print(config)\n",
        "\n",
        "    data_loaders_dict = load_data(config, is_train=False)\n",
        "\n",
        "    reproducible(config.seed)\n",
        "\n",
        "    tester = Tester(data_loaders_dict['test_loader'], config, model_load_path)\n",
        "\n",
        "    metric_values = tester.test()\n",
        "    return metric_values\n",
        "\n",
        "\n",
        "def start_hyper(conf: dict, model: str, dataset: str, seed: int = SINGLE_SEED):\n",
        "    print('Starting Hyperparameter Optimization')\n",
        "    print(f'Seed is {seed}')\n",
        "\n",
        "    # Search Algorithm\n",
        "    search_alg = HyperOptSearch(random_state_seed=seed)\n",
        "\n",
        "    if dataset == 'lfm2b-1mon':\n",
        "        scheduler = ASHAScheduler(grace_period=4)\n",
        "    else:\n",
        "        scheduler = None\n",
        "\n",
        "    # Logger\n",
        "    callback = WandbLoggerCallback(project=PROJECT_NAME, log_config=True, api_key=WANDB_API_KEY,\n",
        "                                   reinit=True, force=True, job_type='train/val', tags=[model, str(seed), dataset])\n",
        "\n",
        "    # Hostname\n",
        "    host_name = platform.uname()\n",
        "\n",
        "    # Dataset\n",
        "    data_path = DATA_PATH\n",
        "    conf['data_path'] = os.path.join(data_path, dataset)\n",
        "\n",
        "    # Seed\n",
        "    conf['seed'] = seed\n",
        "\n",
        "    group_name = f'{model}_{dataset}_{seed}'\n",
        "    tune.register_trainable(group_name, start_training)\n",
        "    analysis = tune.run(\n",
        "        group_name,\n",
        "        config=conf,\n",
        "        name=generate_id(prefix=group_name),\n",
        "        resources_per_trial={'gpu': GPU_PER_TRIAL, 'cpu': CPU_PER_TRIAL},\n",
        "        scheduler=scheduler,\n",
        "        search_alg=search_alg,\n",
        "        num_samples=NUM_SAMPLES,\n",
        "        callbacks=[callback],\n",
        "        metric='_metric/' + OPTIMIZING_METRIC,\n",
        "        mode='max'\n",
        "    )\n",
        "    metric_name = '_metric/' + OPTIMIZING_METRIC\n",
        "    best_trial = analysis.get_best_trial(metric_name, 'max', scope='all')\n",
        "    best_trial_config = best_trial.config\n",
        "    best_trial_checkpoint = os.path.join(analysis.get_best_checkpoint(best_trial, metric_name, 'max'), 'best_model.pth')\n",
        "\n",
        "    wandb.login(key=WANDB_API_KEY)\n",
        "    wandb.init(project=PROJECT_NAME, group='test_results', config=best_trial_config, name=group_name, force=True,\n",
        "               job_type='test', tags=[model, str(seed), dataset])\n",
        "    metric_values = start_testing(best_trial_config, best_trial_checkpoint)\n",
        "    wandb.finish()\n",
        "    return metric_values\n",
        "\n",
        "\n",
        "def start_multiple_hyper(conf: dict, model: str, dataset: str, seed_list: list = SEED_LIST):\n",
        "    print('Starting Multi-Hyperparameter Optimization')\n",
        "    print('seed_list is ', seed_list)\n",
        "    metric_values_list = []\n",
        "    mean_values = dict()\n",
        "\n",
        "    for seed in seed_list:\n",
        "        metric_values_list.append(start_hyper(conf, model, dataset, seed))\n",
        "\n",
        "    for key in metric_values_list[0].keys():\n",
        "        _sum = 0\n",
        "        for metric_values in metric_values_list:\n",
        "            _sum += metric_values[key]\n",
        "        _mean = _sum / len(metric_values_list)\n",
        "\n",
        "        mean_values[key] = _mean\n",
        "\n",
        "    group_name = f'{model}_{dataset}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f6ccf8e1",
      "metadata": {
        "id": "f6ccf8e1"
      },
      "outputs": [],
      "source": [
        "base_param = {\n",
        "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    'n_epochs': 10,\n",
        "    'eval_neg_strategy': 'uniform',\n",
        "    'val_batch_size': 256,\n",
        "    'train_batch_size': 256,\n",
        "    'data_path': protomf_path / \"data/ml\",\n",
        "    'NUM_WORKERS': 1,\n",
        "    'rec_sys_param': {'use_bias': 0},\n",
        "}\n",
        "\n",
        "base_hyper_params = {\n",
        "    **base_param,\n",
        "    'neg_train': 99,\n",
        "    'neg_val': 99,\n",
        "    'train_neg_strategy': 'uniform',#tune.choice(['popular', 'uniform']),\n",
        "    'loss_func_name': 'sampled_softmax', # tune.choice(['bce', 'bpr', 'sampled_softmax']),\n",
        "    'batch_size': np.random.randint(64, 512),\n",
        "    'optim_param': {\n",
        "        'optim': 'adagrad',\n",
        "        'wd': np.random.uniform(low=1e-4, high=1e-2),\n",
        "        'lr': np.random.uniform(low=1e-4, high=1e-1)\n",
        "    },\n",
        "}\n",
        "user_proto_chose_original_hyper_params = {\n",
        "    **base_hyper_params,\n",
        "    'loss_func_aggr': 'mean',\n",
        "    'ft_ext_param': {\n",
        "        \"ft_type\": \"prototypes\",\n",
        "        'embedding_dim': np.random.randint(10, 100), #tune.randint(10, 100),\n",
        "        'user_ft_ext_param': {\n",
        "            \"ft_type\": \"prototypes\",\n",
        "            'sim_proto_weight': np.random.uniform(low=1e-3, high=10), # tune.loguniform(1e-3, 10),\n",
        "            'sim_batch_weight': np.random.uniform(low=1e-3, high=10),\n",
        "            'use_weight_matrix': False,\n",
        "            'n_prototypes': np.random.randint(10, 100), #tune.randint(10, 100),\n",
        "            'cosine_type': 'shifted',\n",
        "            'reg_proto_type': 'max',\n",
        "            'reg_batch_type': 'max',\n",
        "        },\n",
        "        'item_ft_ext_param': {\n",
        "            \"ft_type\": \"embedding\",\n",
        "        }\n",
        "    },\n",
        "}\n",
        "user_proto_chose_original_hyper_params = argparse.Namespace(**user_proto_chose_original_hyper_params)\n",
        "\n",
        "proto_double_tie_chose_original_hyper_params = {\n",
        "    'loss_func_aggr': 'mean',\n",
        "    'ft_ext_param': {\n",
        "        \"ft_type\": \"prototypes_double_tie\",\n",
        "        'embedding_dim': 100, #tune.randint(10, 100),\n",
        "        'item_ft_ext_param': {\n",
        "            \"ft_type\": \"prototypes_double_tie\",\n",
        "            'sim_proto_weight': 1e-3,#tune.loguniform(1e-3, 10),\n",
        "            'sim_batch_weight': 1e-3,#tune.loguniform(1e-3, 10),\n",
        "            'use_weight_matrix': False,\n",
        "            'n_prototypes': 5, #tune.randint(10, 100),\n",
        "            'cosine_type': 'shifted',\n",
        "            'reg_proto_type': 'max',\n",
        "            'reg_batch_type': 'max'\n",
        "        },\n",
        "        'user_ft_ext_param': {\n",
        "            \"ft_type\": \"prototypes_double_tie\",\n",
        "            'sim_proto_weight': 1e-3,#tune.loguniform(1e-3, 10),\n",
        "            'sim_batch_weight': 1e-3, #tune.loguniform(1e-3, 10),\n",
        "            'use_weight_matrix': False,\n",
        "            'n_prototypes': 100, #tune.randint(10, 100),\n",
        "            'cosine_type': 'shifted',\n",
        "            'reg_proto_type': 'max',\n",
        "            'reg_batch_type': 'max'\n",
        "        },\n",
        "    },\n",
        "    \"checkpoint_dir\": 'experiments',\n",
        "    **base_hyper_params,\n",
        "}\n",
        "\n",
        "from omegaconf import OmegaConf\n",
        "# proto_double_tie_chose_original_hyper_params = argparse.Namespace(**proto_double_tie_chose_original_hyper_params)\n",
        "# proto_double_tie_chose_original_hyper_params = OmegaConf.create(proto_double_tie_chose_original_hyper_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d16066d6",
      "metadata": {
        "id": "d16066d6"
      },
      "outputs": [],
      "source": [
        "# data_loaders_dict = load_data(proto_double_tie_chose_original_hyper_params)\n",
        "# config = proto_double_tie_chose_original_hyper_params\n",
        "# trainer = Trainer(data_loaders_dict['train_loader'], data_loaders_dict['val_loader'],  config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "1459be54",
      "metadata": {
        "id": "1459be54"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "'user_ft_ext_param'  'n_prototypes': 5,,\n",
        "'item_ft_ext_param' 'n_prototypes': 5,\n",
        " 'embedding_dim': 100,\n",
        "\"\"\"\n",
        "def objective(trial):\n",
        "    prototypes1 = trial.suggest_int('prototypes1', 20, 100, 20)\n",
        "    prototypes2 = trial.suggest_int('prototypes2', 20, 100, 20)\n",
        "\n",
        "    embeddings_dim = trial.suggest_int(\"embedding\", 50, 400, 50)\n",
        "\n",
        "    proto_double_tie_chose_original_hyper_params['ft_ext_param']['user_ft_ext_param']['n_prototypes'] = prototypes1\n",
        "    proto_double_tie_chose_original_hyper_params['ft_ext_param']['item_ft_ext_param']['n_prototypes'] = prototypes2\n",
        "    proto_double_tie_chose_original_hyper_params['embedding_dim'] = embeddings_dim\n",
        "\n",
        "\n",
        "    config = argparse.Namespace(**proto_double_tie_chose_original_hyper_params)\n",
        "    data_loaders_dict = load_data(config)\n",
        "\n",
        "    trainer = Trainer(data_loaders_dict['train_loader'], data_loaders_dict['val_loader'],  config)\n",
        "\n",
        "    return trainer.run(trial)\n",
        "\n",
        "# study.optimize(objective, n_trials=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e2a21805",
      "metadata": {
        "id": "e2a21805"
      },
      "outputs": [],
      "source": [
        "# class RecSys(nn.Module):\n",
        "\n",
        "#     def __init__(self, n_users: int, n_items: int, rec_sys_param, user_feature_extractor: FeatureExtractor,\n",
        "#                  item_feature_extractor: FeatureExtractor, loss_func_name: str, loss_func_aggr: str = 'mean'):\n",
        "#         \"\"\"\n",
        "#         General Recommender System\n",
        "#         It generates the user/item vectors (given the feature extractors) and computes the similarity by the dot product.\n",
        "#         :param n_users: number of users in the system\n",
        "#         :param n_items: number of items in the system\n",
        "#         :param rec_sys_param: parameters of the Recommender System module\n",
        "#         :param user_feature_extractor: feature_extractor.FeatureExtractor module that generates user embeddings.\n",
        "#         :param item_feature_extractor: feature_extractor.FeatureExtractor module that generates item embeddings.\n",
        "#         :param loss_func_name: name of the loss function to use for the network.\n",
        "#         :param loss_func_aggr: type of aggregation for the loss function, either 'mean' or 'sum'.\n",
        "#         \"\"\"\n",
        "\n",
        "#         assert loss_func_aggr in ['mean', 'sum'], f'Loss function aggregators <{loss_func_aggr}> not implemented...yet'\n",
        "\n",
        "#         super().__init__()\n",
        "#         self.n_users = n_users\n",
        "#         self.n_items = n_items\n",
        "#         self.rec_sys_param = rec_sys_param\n",
        "#         self.user_feature_extractor = user_feature_extractor\n",
        "#         self.item_feature_extractor = item_feature_extractor\n",
        "#         self.loss_func_name = loss_func_name\n",
        "#         self.loss_func_aggr = loss_func_aggr\n",
        "\n",
        "#         self.use_bias = self.rec_sys_param[\"use_bias\"] > 0 if 'use_bias' in self.rec_sys_param else True\n",
        "\n",
        "#         if self.use_bias:\n",
        "#             self.user_bias = nn.Embedding(self.n_users, 1)\n",
        "#             self.item_bias = nn.Embedding(self.n_items, 1)\n",
        "#             self.global_bias = nn.Parameter(torch.zeros(1), requires_grad=True)\n",
        "\n",
        "#         if self.loss_func_name == 'bce':\n",
        "#             self.rec_loss = partial(bce_loss, aggregator=self.loss_func_aggr)\n",
        "#         elif self.loss_func_name == 'bpr':\n",
        "#             self.rec_loss = partial(bpr_loss, aggregator=self.loss_func_aggr)\n",
        "#         elif self.loss_func_name == 'sampled_softmax':\n",
        "#             self.rec_loss = partial(sampled_softmax_loss, aggregator=self.loss_func_aggr)\n",
        "#         else:\n",
        "#             raise ValueError(f'Recommender System Loss function <{self.rec_loss}> Not Implemented... Yet')\n",
        "\n",
        "#         self.initialized = False\n",
        "\n",
        "#         print(f'Built RecSys module \\n'\n",
        "#               f'- n_users: {self.n_users} \\n'\n",
        "#               f'- n_items: {self.n_items} \\n'\n",
        "#               f'- user_feature_extractor: {self.user_feature_extractor.name} \\n'\n",
        "#               f'- item_feature_extractor: {self.item_feature_extractor.name} \\n'\n",
        "#               f'- loss_func_name: {self.loss_func_name} \\n'\n",
        "#               f'- use_bias: {self.use_bias} \\n')\n",
        "\n",
        "#     def init_parameters(self):\n",
        "#         \"\"\"\n",
        "#         Method for initializing the Recommender System Processor\n",
        "#         \"\"\"\n",
        "#         if self.use_bias:\n",
        "#             torch.nn.init.constant_(self.user_bias.weight, 0.)\n",
        "#             torch.nn.init.constant_(self.item_bias.weight, 0.)\n",
        "\n",
        "#         self.user_feature_extractor.init_parameters()\n",
        "#         self.item_feature_extractor.init_parameters()\n",
        "\n",
        "#         self.initialized = True\n",
        "\n",
        "#     def loss_func(self, logits, labels):\n",
        "#         \"\"\"\n",
        "#         Loss function of the Recommender System module. It takes into account eventual feature_extractor loss terms.\n",
        "#         NB. Any feature_extractor loss is pre-weighted.\n",
        "#         :param logits: output of the system.\n",
        "#         :param labels: binary labels\n",
        "#         :return: aggregated loss\n",
        "#         \"\"\"\n",
        "\n",
        "#         rec_loss = self.rec_loss(logits, labels)\n",
        "#         item_feat_ext_loss = self.item_feature_extractor.get_and_reset_loss()\n",
        "#         user_feat_ext_loss = self.user_feature_extractor.get_and_reset_loss()\n",
        "#         return rec_loss + item_feat_ext_loss + user_feat_ext_loss\n",
        "\n",
        "#     def forward(self, u_idxs, i_idxs):\n",
        "#         \"\"\"\n",
        "#         Performs the forward pass considering user indexes and the item indexes. Negative Sampling is done automatically\n",
        "#         by the dataloader\n",
        "#         :param u_idxs: User indexes. Shape is (batch_size,)\n",
        "#         :param i_idxs: Item indexes. Shape is (batch_size, n_neg + 1)\n",
        "\n",
        "#         :return: A matrix of logits values. Shape is (batch_size, 1 + n_neg). First column is always associated\n",
        "#                 to the positive track.\n",
        "#         \"\"\"\n",
        "#         assert self.initialized, 'Model initialization has not been called! Please call .init_parameters() ' \\\n",
        "#                                  'before using the model'\n",
        "\n",
        "#         # --- User pass ---\n",
        "#         u_embed = self.user_feature_extractor(u_idxs)\n",
        "#         if self.use_bias:\n",
        "#             u_bias = self.user_bias(u_idxs)\n",
        "\n",
        "#         # --- Item pass ---\n",
        "#         if self.use_bias:\n",
        "#             i_bias = self.item_bias(i_idxs).squeeze()\n",
        "\n",
        "#         i_embed = self.item_feature_extractor(i_idxs)\n",
        "\n",
        "#         # --- Dot Product ---\n",
        "#         dots = torch.sum(u_embed.unsqueeze(1) * i_embed, dim=-1)  # [batch_size, n_neg_p_1]\n",
        "\n",
        "#         if self.use_bias:\n",
        "#             # Optional bias\n",
        "#             dots = dots + u_bias + i_bias + self.global_bias\n",
        "\n",
        "#         return dots\n",
        "\n",
        "\n",
        "# def bce_loss(logits, labels, aggregator='mean'):\n",
        "#     \"\"\"\n",
        "#     It computes the binary cross entropy loss with negative sampling, expressed by the formula:\n",
        "#                                     -∑_j log(x_ui) + log(1 - x_uj)\n",
        "#     where x_ui and x_uj are the prediction for user u on item i and j, respectively. Item i positive instance while\n",
        "#     Item j is a negative instance. The Sum is carried out across the different negative instances. In other words\n",
        "#     the positive item is weighted as many as negative items are considered.\n",
        "\n",
        "#     :param logits: Logits values from the network. The first column always contain the values of positive instances.\n",
        "#             Shape is (batch_size, 1 + n_neg).\n",
        "#     :param labels: 1-0 Labels. The first column contains 1s while all the others 0s.\n",
        "#     :param aggregator: function to use to aggregate the loss terms. Default to mean\n",
        "\n",
        "#     :return: The binary cross entropy as computed above\n",
        "#     \"\"\"\n",
        "#     weights = torch.ones_like(logits)\n",
        "#     weights[:, 0] = logits.shape[1] - 1\n",
        "\n",
        "#     loss = nn.BCEWithLogitsLoss(weights.flatten(), reduction=aggregator)(logits.flatten(), labels.flatten())\n",
        "\n",
        "#     return loss\n",
        "\n",
        "\n",
        "# def bpr_loss(logits, labels, aggregator='mean'):\n",
        "#     \"\"\"\n",
        "#     It computes the Bayesian Personalized Ranking loss (https://arxiv.org/pdf/1205.2618.pdf).\n",
        "\n",
        "#     :param logits: Logits values from the network. The first column always contain the values of positive instances.\n",
        "#             Shape is (batch_size, 1 + n_neg).\n",
        "#     :param labels: 1-0 Labels. The first column contains 1s while all the others 0s.\n",
        "#     :param aggregator: function to use to aggregate the loss terms. Default to mean\n",
        "\n",
        "#     :return: The bayesian personalized ranking loss\n",
        "#     \"\"\"\n",
        "#     pos_logits = logits[:, 0].unsqueeze(1)  # [batch_size,1]\n",
        "#     neg_logits = logits[:, 1:]  # [batch_size,n_neg]\n",
        "\n",
        "#     labels = labels[:, 0]  # I guess this is just to avoid problems with the device\n",
        "#     labels = torch.repeat_interleave(labels, neg_logits.shape[1])\n",
        "\n",
        "#     diff_logits = pos_logits - neg_logits\n",
        "\n",
        "#     loss = nn.BCEWithLogitsLoss(reduction=aggregator)(diff_logits.flatten(), labels.flatten())\n",
        "\n",
        "#     return loss\n",
        "\n",
        "\n",
        "# def sampled_softmax_loss(logits, labels, aggregator='sum'):\n",
        "#     \"\"\"\n",
        "#     It computes the (Sampled) Softmax Loss (a.k.a. sampled cross entropy) expressed by the formula:\n",
        "#                         -x_ui +  log( ∑_j e^{x_uj})\n",
        "#     where x_ui and x_uj are the prediction for user u on item i and j, respectively. Item i positive instance while j\n",
        "#     goes over all the sampled items (negatives + the positive).\n",
        "#     :param logits: Logits values from the network. The first column always contain the values of positive instances.\n",
        "#             Shape is (batch_size, 1 + n_neg).\n",
        "#     :param labels: 1-0 Labels. The first column contains 1s while all the others 0s.\n",
        "#     :param aggregator: function to use to aggregate the loss terms. Default to sum\n",
        "#     :return:\n",
        "#     \"\"\"\n",
        "\n",
        "#     pos_logits_sum = - logits[:, 0]\n",
        "#     log_sum_exp_sum = torch.logsumexp(logits, dim=-1)\n",
        "\n",
        "#     sampled_loss = pos_logits_sum + log_sum_exp_sum\n",
        "\n",
        "#     if aggregator == 'sum':\n",
        "#         return sampled_loss.sum()\n",
        "#     elif aggregator == 'mean':\n",
        "#         return sampled_loss.mean()\n",
        "#     else:\n",
        "#         raise ValueError('Loss aggregator not defined')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "96812ea6",
      "metadata": {
        "id": "96812ea6"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = Path(\"./ProtoMF/best_models\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "55f30b9a",
      "metadata": {
        "id": "55f30b9a"
      },
      "outputs": [],
      "source": [
        "# class Trainer:\n",
        "\n",
        "#     def __init__(self, train_loader: data.DataLoader, val_loader: data.DataLoader, conf):\n",
        "#         \"\"\"\n",
        "#         Train and Evaluate the model.\n",
        "#         :param train_loader: Training DataLoader (check music4all_data.Music4AllDataset for more info)\n",
        "#         :param val_loader: Validation DataLoader (check music4all_data.Music4AllDataset for more info)\n",
        "#         :param conf: Experiment configuration parameters\n",
        "#         \"\"\"\n",
        "\n",
        "#         self.train_loader = train_loader\n",
        "#         self.val_loader = val_loader\n",
        "\n",
        "#         self.rec_sys_param = conf.rec_sys_param\n",
        "#         self.ft_ext_param = conf.ft_ext_param\n",
        "#         self.optim_param = conf.optim_param\n",
        "\n",
        "#         self.n_epochs = conf.n_epochs\n",
        "#         self.loss_func_name = conf.loss_func_name\n",
        "#         self.loss_func_aggr = conf.loss_func_aggr if 'loss_func_aggr' in conf else 'mean'\n",
        "\n",
        "#         self.device = conf.device\n",
        "\n",
        "#         self.optimizing_metric = OPTIMIZING_METRIC\n",
        "#         self.max_patience = MAX_PATIENCE\n",
        "\n",
        "#         self.model = self._build_model()\n",
        "#         self.optimizer = self._build_optimizer()\n",
        "\n",
        "#         print(f'Built Trainer module \\n'\n",
        "#               f'- n_epochs: {self.n_epochs} \\n'\n",
        "#               f'- loss_func_name: {self.loss_func_name} \\n'\n",
        "#               f'- loss_func_aggr: {self.loss_func_aggr} \\n'\n",
        "#               f'- device: {self.device} \\n'\n",
        "#               f'- optimizing_metric: {self.optimizing_metric} \\n')\n",
        "\n",
        "#     def _build_model(self):\n",
        "#         # Step 1 --- Building User and Item Feature Extractors\n",
        "#         n_users = self.train_loader.dataset.n_users\n",
        "#         n_items = self.train_loader.dataset.n_items\n",
        "#         user_feature_extractor, item_feature_extractor = \\\n",
        "#             FeatureExtractorFactory.create_models(self.ft_ext_param, n_users, n_items)\n",
        "#         # Step 2 --- Building RecSys Module\n",
        "#         rec_sys = RecSys(n_users, n_items, self.rec_sys_param, user_feature_extractor, item_feature_extractor,\n",
        "#                          self.loss_func_name, self.loss_func_aggr)\n",
        "\n",
        "#         rec_sys.init_parameters()\n",
        "#         rec_sys = nn.DataParallel(rec_sys)\n",
        "#         rec_sys = rec_sys.to(self.device)\n",
        "\n",
        "#         return rec_sys\n",
        "\n",
        "#     def _build_optimizer(self):\n",
        "#         self.lr = self.optim_param['lr'] if 'lr' in self.optim_param else 1e-3\n",
        "#         self.wd = self.optim_param['wd'] if 'wd' in self.optim_param else 1e-4\n",
        "\n",
        "#         optim_name = self.optim_param['optim']\n",
        "#         if optim_name == 'adam':\n",
        "#             optim = torch.optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=self.wd)\n",
        "#         elif optim_name == 'adagrad':\n",
        "#             optim = torch.optim.Adagrad(self.model.parameters(), lr=self.lr, weight_decay=self.wd)\n",
        "#         else:\n",
        "#             raise ValueError('Optimizer not yet included')\n",
        "\n",
        "#         print(f'Built Optimizer  \\n'\n",
        "#               f'- name: {optim_name} \\n'\n",
        "#               f'- lr: {self.lr} \\n'\n",
        "#               f'- wd: {self.wd} \\n')\n",
        "\n",
        "#         return optim\n",
        "\n",
        "#     def run(self):\n",
        "#         \"\"\"\n",
        "#         Runs the Training procedure\n",
        "#         \"\"\"\n",
        "#         metrics_values = self.val()\n",
        "#         best_value = metrics_values[self.optimizing_metric]\n",
        "# #         tune.report(metrics_values)\n",
        "#         print('Init - Avg Val Value {:.3f} \\n'.format(best_value))\n",
        "\n",
        "#         patience = 0\n",
        "#         for epoch in range(self.n_epochs):\n",
        "\n",
        "#             if patience == self.max_patience:\n",
        "#                 print('Max Patience reached, stopping.')\n",
        "#                 break\n",
        "\n",
        "#             self.model.train()\n",
        "\n",
        "#             epoch_train_loss = 0\n",
        "\n",
        "#             for u_idxs, i_idxs, labels in self.train_loader:\n",
        "#                 # print(u_idxs.shape)\n",
        "#                 # print(i_idxs.shape)\n",
        "#                 # print(labels.shape)\n",
        "\n",
        "#                 u_idxs = u_idxs.to(self.device)\n",
        "#                 i_idxs = i_idxs.to(self.device)\n",
        "#                 labels = labels.to(self.device)\n",
        "\n",
        "#                 out = self.model(u_idxs, i_idxs)\n",
        "\n",
        "#                 loss = self.model.module.loss_func(out, labels)\n",
        "\n",
        "#                 epoch_train_loss += loss.item()\n",
        "\n",
        "#                 loss.backward()\n",
        "#                 self.optimizer.step()\n",
        "#                 self.optimizer.zero_grad()\n",
        "#                 if int(u_idxs[0]) % 1000 == 0:\n",
        "#                     print(str(int(u_idxs[0])) + '_users_past')\n",
        "#             epoch_train_loss /= len(self.train_loader)\n",
        "#             print(\"Epoch {} - Epoch Avg Train Loss {:.3f} \\n\".format(epoch, epoch_train_loss))\n",
        "\n",
        "#             metrics_values = self.val()\n",
        "#             curr_value = metrics_values[self.optimizing_metric]\n",
        "#             print('Epoch {} - Avg Val Value {:.3f} \\n'.format(epoch, curr_value))\n",
        "#             # tune.report({**metrics_values, 'epoch_train_loss': epoch_train_loss})\n",
        "\n",
        "#             if curr_value > best_value:\n",
        "#                 best_value = curr_value\n",
        "#                 print('Epoch {} - New best model found (val value {:.3f}) \\n'.format(epoch, curr_value))\n",
        "#                 torch.save(self.model.module.state_dict(), os.path.join(checkpoint_dir, 'best_model.pth'))\n",
        "#                 patience = 0\n",
        "#             else:\n",
        "#                 patience += 1\n",
        "\n",
        "#     @torch.no_grad()\n",
        "#     def val(self):\n",
        "#         \"\"\"\n",
        "#         Runs the evaluation procedure.\n",
        "#         :return: A scalar float value, output of the validation (e.g. NDCG@10).\n",
        "#         \"\"\"\n",
        "#         self.model.eval()\n",
        "#         print('Validation started')\n",
        "#         val_loss = 0\n",
        "#         eval = Evaluator(self.val_loader.dataset.n_users)\n",
        "\n",
        "#         for u_idxs, i_idxs, labels in self.val_loader:\n",
        "#             u_idxs = u_idxs.to(self.device)\n",
        "#             i_idxs = i_idxs.to(self.device)\n",
        "#             labels = labels.to(self.device)\n",
        "\n",
        "#             out = self.model(u_idxs, i_idxs)\n",
        "\n",
        "#             val_loss += self.model.module.loss_func(out, labels).item()\n",
        "\n",
        "#             out = nn.Sigmoid()(out)\n",
        "#             out = out.to('cpu')\n",
        "\n",
        "#             eval.eval_batch(out)\n",
        "#             if int(u_idxs[0]) % 1000 == 0:\n",
        "#                 print(str(int(u_idxs[0])) + '_users_past')\n",
        "#         val_loss /= len(self.val_loader)\n",
        "#         metrics_values = {**eval.get_results(), 'val_loss': val_loss}\n",
        "\n",
        "#         return metrics_values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ff1b2309",
      "metadata": {
        "id": "ff1b2309"
      },
      "outputs": [],
      "source": [
        "class ProtoRecDataset(data.Dataset):\n",
        "    \"\"\"\n",
        "    Dataset class to be used in ProtoRec. To use this class for any dataset, please refer to the splitter functions\n",
        "    (e.g. movielens_splitter.py)\n",
        "\n",
        "    This class implements some basic functionalities about negative sampling. The negative sampling for a specific user\n",
        "    is influenced by the split_set:\n",
        "        - split_set = train: The other training items are excluded from the sampling.\n",
        "        - split_set = val: The other validation items and training items are excluded from the sampling.\n",
        "        - split_set = test: The other test items and training items are excluded from the sampling.\n",
        "\n",
        "    About the data management and access:\n",
        "    To perform a fast iteration and sampling over the dataset, we use two sparse matrices (COO and CSR). The COO\n",
        "    is used for iteration over the training data while the CSR for fast negative sampling. We always load the train\n",
        "    CSR since it is used to exclude the training data from the negative sampling also for Validation and Testing.\n",
        "    NB. Depending on the split_set, the matrices may have different data. Train COO and Train CSR have always the\n",
        "    same data. However, Val CSR has Val + Train data (same applies for test). This is due to the negative sampling\n",
        "    in the csr matrix, for which we also exclude items from training (see below).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_path: str, split_set: str, n_neg: int, neg_strategy: str = 'uniform'):\n",
        "        \"\"\"\n",
        "        :param data_path: path to the directory with the listening_history_*, item_ids, and user_ids files.\n",
        "        :param split_set: Value in [train, val, test].\n",
        "        :param n_neg: Number of negative samples.\n",
        "        :param neg_strategy: Strategy to select the negative samples.\n",
        "        \"\"\"\n",
        "        assert split_set in ['train', 'val', 'test'], f'<{split_set}> is not a valid value for split set!'\n",
        "\n",
        "        self.data_path = data_path\n",
        "        self.split_set = split_set\n",
        "        self.n_neg = n_neg\n",
        "        self.neg_strategy = neg_strategy\n",
        "\n",
        "        self.n_users = None\n",
        "        self.n_items = None\n",
        "\n",
        "        self.item_ids = None\n",
        "\n",
        "        self.coo_matrix = None\n",
        "        self.csr_matrix = None\n",
        "\n",
        "        self.pop_distribution = None\n",
        "\n",
        "        self.load_data()\n",
        "\n",
        "        print(f'Built ProtoRecDataset module \\n'\n",
        "              f'- data_path: {self.data_path} \\n'\n",
        "              f'- n_users: {self.n_users} \\n'\n",
        "              f'- n_items: {self.n_items} \\n'\n",
        "              f'- n_interactions: {self.coo_matrix.nnz} \\n'\n",
        "              f'- split_set: {self.split_set} \\n'\n",
        "              f'- n_neg: {self.n_neg} \\n'\n",
        "              f'- neg_strategy: {self.neg_strategy} \\n')\n",
        "\n",
        "    def load_data(self):\n",
        "        print('Loading data')\n",
        "\n",
        "        user_ids = pd.read_csv(os.path.join(self.data_path, 'user_ids.csv'))\n",
        "        item_ids = pd.read_csv(os.path.join(self.data_path, 'item_ids.csv'))\n",
        "\n",
        "        self.n_users = len(user_ids)\n",
        "        self.n_items = len(item_ids)\n",
        "\n",
        "        train_lhs = pd.read_csv(os.path.join(self.data_path, 'listening_history_train.csv'))\n",
        "\n",
        "        train_csr = sp.csr_matrix(\n",
        "            (np.ones(len(train_lhs), dtype=np.int16), (train_lhs.user_id, train_lhs.item_id)),\n",
        "            shape=(self.n_users, self.n_items))\n",
        "\n",
        "        # Computing the popularity distribution (see _neg_sample_popular)\n",
        "        item_popularity = np.array(train_csr.sum(axis=0)).flatten()\n",
        "        self.pop_distribution = item_popularity / item_popularity.sum()\n",
        "\n",
        "        if self.split_set == 'val':\n",
        "            val_lhs = pd.read_csv(os.path.join(self.data_path, 'listening_history_val.csv'))\n",
        "\n",
        "            val_csr = sp.csr_matrix(\n",
        "                (np.ones(len(val_lhs), dtype=np.int16), (val_lhs.user_id, val_lhs.item_id)),\n",
        "                shape=(self.n_users, self.n_items))\n",
        "\n",
        "            val_coo = sp.coo_matrix(val_csr)\n",
        "\n",
        "            self.coo_matrix = val_coo\n",
        "            self.csr_matrix = val_csr + train_csr\n",
        "\n",
        "        elif self.split_set == 'test':\n",
        "            test_lhs = pd.read_csv(os.path.join(self.data_path, 'listening_history_test.csv'))\n",
        "\n",
        "            test_csr = sp.csr_matrix(\n",
        "                (np.ones(len(test_lhs), dtype=np.int16), (test_lhs.user_id, test_lhs.item_id)),\n",
        "                shape=(self.n_users, self.n_items))\n",
        "\n",
        "            test_coo = sp.coo_matrix(test_csr)\n",
        "\n",
        "            self.coo_matrix = test_coo\n",
        "            self.csr_matrix = test_csr + train_csr\n",
        "\n",
        "        elif self.split_set == 'train':\n",
        "            train_coo = sp.coo_matrix(train_csr)\n",
        "\n",
        "            self.coo_matrix = train_coo\n",
        "            self.csr_matrix = train_csr\n",
        "\n",
        "    def _neg_sample_uniform(self, row_idx: int) -> np.array:\n",
        "        \"\"\"\n",
        "        For a specific user, it samples n_neg items u.a.r.\n",
        "        :param row_idx: user id (or row in the matrix)\n",
        "        :return: npy array containing the negatively sampled items.\n",
        "        \"\"\"\n",
        "\n",
        "        consumed_items = self.csr_matrix.indices[self.csr_matrix.indptr[row_idx]:self.csr_matrix.indptr[row_idx + 1]]\n",
        "\n",
        "        # Uniform distribution without items consumed by the user\n",
        "        p = np.ones(self.n_items)\n",
        "        p[consumed_items] = 0.  # Excluding consumed items\n",
        "        p = p / p.sum()\n",
        "\n",
        "        sampled = np.random.choice(np.arange(self.n_items), self.n_neg, replace=False, p=p)\n",
        "\n",
        "        return sampled\n",
        "\n",
        "    def _neg_sample_popular(self, row_idx: int) -> np.array:\n",
        "        \"\"\"\n",
        "        For a specific user, it samples n_neg items considering the frequency of appearance of items in the dataset, i.e.\n",
        "        p(i being neg) ∝ (pop_i)^0.75.\n",
        "        :param row_idx: user id (or row in the matrix)\n",
        "        :return: npy array containing the negatively sampled items.\n",
        "        \"\"\"\n",
        "        consumed_items = self.csr_matrix.indices[self.csr_matrix.indptr[row_idx]:self.csr_matrix.indptr[row_idx + 1]]\n",
        "\n",
        "        p = self.pop_distribution.copy()\n",
        "        p[consumed_items] = 0.  # Excluding consumed items\n",
        "        p = np.power(p, .75)  # Squashing factor alpha = .75\n",
        "        p = p / p.sum()\n",
        "\n",
        "        sampled = np.random.choice(np.arange(self.n_items), self.n_neg, replace=False, p=p)\n",
        "        return sampled\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.coo_matrix.nnz\n",
        "\n",
        "    def __getitem__(self, index) -> T_co:\n",
        "        \"\"\"\n",
        "        Loads the (user,item) pair associated to the index and performs the negative sampling.\n",
        "        :param index: (user,item) index pair (as defined by the COO.data vector)\n",
        "        :return: (user_idx,item_idxs,labels) where\n",
        "            user_idx: is the index of the user\n",
        "            item_idxs: is a npy array containing the items indexes. The positive item is in the 1st position followed\n",
        "                        by the negative items indexes. Shape is (1 + n_neg,)\n",
        "            labels: npy array containing the labels. First position is 1, the others are 0. Shape is (1 + n_neg,).\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        user_idx = self.coo_matrix.row[index].astype('int64')\n",
        "        item_idx_pos = self.coo_matrix.col[index]\n",
        "\n",
        "        # Select the correct negative sampling strategy\n",
        "        if self.neg_strategy == 'uniform':\n",
        "            neg_samples = self._neg_sample_uniform(user_idx)\n",
        "        elif self.neg_strategy == 'popular':\n",
        "            neg_samples = self._neg_sample_popular(user_idx)\n",
        "        else:\n",
        "            raise ValueError(f'Negative Sampling Strategy <{self.neg_strategy}> not implemented ... Yet')\n",
        "\n",
        "        item_idxs = np.concatenate(([item_idx_pos], neg_samples)).astype('int64')\n",
        "\n",
        "        labels = np.zeros(1 + self.n_neg, dtype='float32')\n",
        "        labels[0] = 1.\n",
        "\n",
        "        return user_idx, item_idxs, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Working with data. Download (not see)"
      ],
      "metadata": {
        "id": "nYyIcEKZpMs7"
      },
      "id": "nYyIcEKZpMs7"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3b6bd828",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b6bd828",
        "outputId": "098d9cdb-6b9f-4f48-f36e-2d8e6b1d4d68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data\n",
            "Built ProtoRecDataset module \n",
            "- data_path: ./ProtoMF/data/full_train \n",
            "- n_users: 6028 \n",
            "- n_items: 3123 \n",
            "- n_interactions: 559852 \n",
            "- split_set: train \n",
            "- n_neg: 10 \n",
            "- neg_strategy: uniform \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0,\n",
              " array([ 222, 1100, 1361, 2366, 2555, 3101,  966, 2325, 2246, 1017,  796]),\n",
              " array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "data_path = './ProtoMF/data/full_train' #Path(r\".\\ProtoMF\\data\\full_train\")\n",
        "\n",
        "dataset = 'ml'\n",
        "tst= ProtoRecDataset(data_path, 'train', 10, 'uniform')\n",
        "tst.__getitem__(0)\n",
        "tst2 = data.DataLoader(tst)\n",
        "tst2\n",
        "\n",
        "tst.__getitem__(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "e93f4018",
      "metadata": {
        "id": "e93f4018"
      },
      "outputs": [],
      "source": [
        "def get_protorecdataset_dataloader(data_path: str, split_set: str, n_neg: int, neg_strategy='uniform',\n",
        "                                   **loader_params) -> data.DataLoader:\n",
        "    \"\"\"\n",
        "    Returns the dataloader for a ProtoRecDataset\n",
        "    :param data_path, ... ,neg_strategy: check ProtoRecDataset class for info about these parameters\n",
        "    :param loader_params: parameters for the Dataloader\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    protorec_dataset = ProtoRecDataset(data_path, split_set, n_neg, neg_strategy)\n",
        "    return data.DataLoader(protorec_dataset, **loader_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "56b296c5",
      "metadata": {
        "id": "56b296c5"
      },
      "outputs": [],
      "source": [
        "def load_data(conf, is_train: bool = True):\n",
        "    if is_train:\n",
        "        train_loader = get_protorecdataset_dataloader(\n",
        "        data_path= conf.data_path,\n",
        "        split_set='train',\n",
        "        n_neg=conf.neg_train,\n",
        "        neg_strategy=conf.train_neg_strategy,\n",
        "        batch_size=conf.train_batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=conf.NUM_WORKERS,\n",
        "        prefetch_factor=5\n",
        "    )\n",
        "\n",
        "        val_loader = get_protorecdataset_dataloader(\n",
        "            data_path=conf.data_path,\n",
        "            split_set='val',\n",
        "            n_neg=conf.neg_val,\n",
        "            neg_strategy=conf.eval_neg_strategy,\n",
        "            batch_size=conf.val_batch_size,\n",
        "            num_workers=conf.NUM_WORKERS\n",
        "        )\n",
        "\n",
        "        test_loader = get_protorecdataset_dataloader(\n",
        "            data_path=conf.data_path,\n",
        "            split_set='test',\n",
        "            n_neg=conf.neg_val,\n",
        "            neg_strategy=conf.eval_neg_strategy,\n",
        "            batch_size=conf.val_batch_size,\n",
        "            num_workers=conf.NUM_WORKERS\n",
        "        )\n",
        "\n",
        "        return {'train_loader': train_loader, 'val_loader': val_loader, 'test_loader': test_loader}\n",
        "    else:\n",
        "\n",
        "        test_loader = get_protorecdataset_dataloader(\n",
        "            data_path=conf.data_path,\n",
        "            split_set='test',\n",
        "            n_neg=conf.neg_val,\n",
        "            neg_strategy=conf.eval_neg_strategy,\n",
        "            batch_size=conf.val_batch_size,\n",
        "            num_workers=conf.NUM_WORKERS\n",
        "        )\n",
        "\n",
        "        return {'test_loader': test_loader}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "4c4bfd87",
      "metadata": {
        "scrolled": true,
        "id": "4c4bfd87"
      },
      "outputs": [],
      "source": [
        "# data_loaders_dict = load_data(user_proto_chose_original_hyper_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "8e6f023c",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e6f023c",
        "outputId": "3150b040-5a20-4d06-a2ab-1fd76bcb9cc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data\n",
            "Built ProtoRecDataset module \n",
            "- data_path: ProtoMF/data/full_train \n",
            "- n_users: 6028 \n",
            "- n_items: 3123 \n",
            "- n_interactions: 559852 \n",
            "- split_set: train \n",
            "- n_neg: 99 \n",
            "- neg_strategy: uniform \n",
            "\n",
            "Loading data\n",
            "Built ProtoRecDataset module \n",
            "- data_path: ProtoMF/data/full_train \n",
            "- n_users: 6028 \n",
            "- n_items: 3123 \n",
            "- n_interactions: 13952 \n",
            "- split_set: val \n",
            "- n_neg: 99 \n",
            "- neg_strategy: uniform \n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_loader = get_protorecdataset_dataloader(protomf_path / \"data/full_train\", 'train', 99, batch_size = 64)\n",
        "val_loader = get_protorecdataset_dataloader(protomf_path / \"data/full_train\", 'val', 99, batch_size = 64)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Trainer configs, initialise and build (not see)"
      ],
      "metadata": {
        "id": "s9YrJEzMpjlf"
      },
      "id": "s9YrJEzMpjlf"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "3f902bd0",
      "metadata": {
        "id": "3f902bd0"
      },
      "outputs": [],
      "source": [
        "# from omegaconf import OmegaConf\n",
        "\n",
        "# OmegaConf.create(proto_double_tie_chose_original_hyper_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "2b3c4c1c",
      "metadata": {
        "id": "2b3c4c1c"
      },
      "outputs": [],
      "source": [
        "base_param = {\n",
        "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    'n_epochs': 10,\n",
        "    'eval_neg_strategy': 'uniform',\n",
        "    'val_batch_size': 64,\n",
        "    'train_batch_size': 64,\n",
        "    'data_path': protomf_path / \"data/ml\",\n",
        "    'NUM_WORKERS': 1,\n",
        "    'rec_sys_param': {'use_bias': 0},\n",
        "}\n",
        "\n",
        "base_hyper_params = {\n",
        "    **base_param,\n",
        "    'neg_train': 99,\n",
        "    'neg_val': 99,\n",
        "    'train_neg_strategy': 'uniform',#tune.choice(['popular', 'uniform']),\n",
        "    'loss_func_name': 'sampled_softmax', # tune.choice(['bce', 'bpr', 'sampled_softmax']),\n",
        "    'batch_size': 64,\n",
        "    'optim_param': {\n",
        "        'optim': 'adagrad',\n",
        "        'wd': 1e-4,\n",
        "        'lr': 1e-3\n",
        "    },\n",
        "}\n",
        "\n",
        "proto_double_tie_optimal_params = {\n",
        "    'loss_func_aggr': 'mean',\n",
        "    'ft_ext_param': {\n",
        "        \"ft_type\": \"prototypes_double_tie\",\n",
        "        'embedding_dim': 300, #tune.randint(10, 100),\n",
        "        'item_ft_ext_param': {\n",
        "            \"ft_type\": \"prototypes_double_tie\",\n",
        "            'sim_proto_weight': 1e-3,#tune.loguniform(1e-3, 10),\n",
        "            'sim_batch_weight': 1e-3,#tune.loguniform(1e-3, 10),\n",
        "            'use_weight_matrix': False,\n",
        "            'n_prototypes': 80, #tune.randint(10, 100),\n",
        "            'cosine_type': 'shifted',\n",
        "            'reg_proto_type': 'max',\n",
        "            'reg_batch_type': 'max'\n",
        "        },\n",
        "        'user_ft_ext_param': {\n",
        "            \"ft_type\": \"prototypes_double_tie\",\n",
        "            'sim_proto_weight': 1e-3,#tune.loguniform(1e-3, 10),\n",
        "            'sim_batch_weight': 1e-3, #tune.loguniform(1e-3, 10),\n",
        "            'use_weight_matrix': False,\n",
        "            'n_prototypes': 80, #tune.randint(10, 100),\n",
        "            'cosine_type': 'shifted',\n",
        "            'reg_proto_type': 'max',\n",
        "            'reg_batch_type': 'max'\n",
        "        },\n",
        "    },\n",
        "    \"checkpoint_dir\": 'experiments/full_train',\n",
        "    **base_hyper_params,\n",
        "}\n",
        "\n",
        "from omegaconf import OmegaConf\n",
        "# proto_double_tie_chose_original_hyper_params = argparse.Namespace(**proto_double_tie_chose_original_hyper_params)\n",
        "# proto_double_tie_chose_original_hyper_params = OmegaConf.create(proto_double_tie_chose_original_hyper_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "aa1b5e4b",
      "metadata": {
        "id": "aa1b5e4b"
      },
      "outputs": [],
      "source": [
        "base_param = {\n",
        "    'device': 'cuda',\n",
        "    'n_epochs': 10,\n",
        "    'eval_neg_strategy': 'uniform',\n",
        "    'val_batch_size': 64,\n",
        "    'train_batch_size': 64,\n",
        "    'data_path': protomf_path / \"data/ml\",\n",
        "    'NUM_WORKERS': 1,\n",
        "    'rec_sys_param': {'use_bias': 0},\n",
        "}\n",
        "\n",
        "base_hyper_params = {\n",
        "    **base_param,\n",
        "    'neg_train': 99,\n",
        "    'neg_val': 99,\n",
        "    'train_neg_strategy': 'uniform',#tune.choice(['popular', 'uniform']),\n",
        "    'loss_func_name': 'sampled_softmax', # tune.choice(['bce', 'bpr', 'sampled_softmax']),\n",
        "    'batch_size': 64,\n",
        "    'optim_param': {\n",
        "        'optim': 'adagrad',\n",
        "        'wd': 1e-4,\n",
        "        'lr': 1e-3\n",
        "    },\n",
        "}\n",
        "\n",
        "proto_double_tie_optimal_params = {\n",
        "    'loss_func_aggr': 'mean',\n",
        "    'ft_ext_param': {\n",
        "        \"ft_type\": \"prototypes_double_tie\",\n",
        "        'embedding_dim': 300, #tune.randint(10, 100),\n",
        "        'item_ft_ext_param': {\n",
        "            \"ft_type\": \"prototypes_double_tie\",\n",
        "            'sim_proto_weight': 1e-3,#tune.loguniform(1e-3, 10),\n",
        "            'sim_batch_weight': 1e-3,#tune.loguniform(1e-3, 10),\n",
        "            'use_weight_matrix': False,\n",
        "            'n_prototypes': 80, #tune.randint(10, 100),\n",
        "            'cosine_type': 'shifted',\n",
        "            'reg_proto_type': 'max',\n",
        "            'reg_batch_type': 'max'\n",
        "        },\n",
        "        'user_ft_ext_param': {\n",
        "            \"ft_type\": \"prototypes_double_tie\",\n",
        "            'sim_proto_weight': 1e-3,#tune.loguniform(1e-3, 10),\n",
        "            'sim_batch_weight': 1e-3, #tune.loguniform(1e-3, 10),\n",
        "            'use_weight_matrix': False,\n",
        "            'n_prototypes': 80, #tune.randint(10, 100),\n",
        "            'cosine_type': 'shifted',\n",
        "            'reg_proto_type': 'max',\n",
        "            'reg_batch_type': 'max'\n",
        "        },\n",
        "    },\n",
        "    \"checkpoint_dir\": 'experiments/full_train',\n",
        "    **base_hyper_params,\n",
        "}\n",
        "\n",
        "from omegaconf import OmegaConf\n",
        "# proto_double_tie_chose_original_hyper_params = argparse.Namespace(**proto_double_tie_chose_original_hyper_params)\n",
        "# proto_double_tie_chose_original_hyper_params = OmegaConf.create(proto_double_tie_chose_original_hyper_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "ab7f1df3",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab7f1df3",
        "outputId": "e87dacbe-4385-4741-ea43-6ae4a193e712"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Building FeatureExtractor model ---\n",
            "Built Embedding model \n",
            "- n_objects: 6028 \n",
            "- embedding_dim: 300 \n",
            "- max_norm: None\n",
            "- only_positive: False\n",
            "Built PrototypeEmbedding model \n",
            "- n_prototypes: 80 \n",
            "- use_weight_matrix: False \n",
            "- sim_proto_weight: 0.001 \n",
            "- sim_batch_weight: 0.001 \n",
            "- reg_proto_type: max \n",
            "- reg_batch_type: max \n",
            "- cosine_type: shifted \n",
            "\n",
            "--- Finished building FeatureExtractor model ---\n",
            "\n",
            "--- Building FeatureExtractor model ---\n",
            "Built Embedding model \n",
            "- n_objects: 6028 \n",
            "- embedding_dim: 300 \n",
            "- max_norm: None\n",
            "- only_positive: False\n",
            "Built Embeddingw model \n",
            "- out_dimension: 80 \n",
            "- use_bias: False \n",
            "\n",
            "--- Finished building FeatureExtractor model ---\n",
            "\n",
            "--- Building FeatureExtractor model ---\n",
            "Built Embedding model \n",
            "- n_objects: 3123 \n",
            "- embedding_dim: 300 \n",
            "- max_norm: None\n",
            "- only_positive: False\n",
            "Built PrototypeEmbedding model \n",
            "- n_prototypes: 80 \n",
            "- use_weight_matrix: False \n",
            "- sim_proto_weight: 0.001 \n",
            "- sim_batch_weight: 0.001 \n",
            "- reg_proto_type: max \n",
            "- reg_batch_type: max \n",
            "- cosine_type: shifted \n",
            "\n",
            "--- Finished building FeatureExtractor model ---\n",
            "\n",
            "--- Building FeatureExtractor model ---\n",
            "Built Embedding model \n",
            "- n_objects: 3123 \n",
            "- embedding_dim: 300 \n",
            "- max_norm: None\n",
            "- only_positive: False\n",
            "Built Embeddingw model \n",
            "- out_dimension: 80 \n",
            "- use_bias: False \n",
            "\n",
            "--- Finished building FeatureExtractor model ---\n",
            "\n",
            "Built ConcatenateFeatureExtractors model \n",
            "- model_1: PrototypeEmbedding \n",
            "- model_2: EmbeddingW \n",
            "- invert: False \n",
            "\n",
            "Built ConcatenateFeatureExtractors model \n",
            "- model_1: PrototypeEmbedding \n",
            "- model_2: EmbeddingW \n",
            "- invert: True \n",
            "\n",
            "Built RecSys module \n",
            "- n_users: 6028 \n",
            "- n_items: 3123 \n",
            "- user_feature_extractor: ConcatenateFeatureExtractors \n",
            "- item_feature_extractor: ConcatenateFeatureExtractors \n",
            "- loss_func_name: sampled_softmax \n",
            "- use_bias: False \n",
            "\n",
            "Built Optimizer  \n",
            "- name: adagrad \n",
            "- lr: 0.001 \n",
            "- wd: 0.0001 \n",
            "\n",
            "Built Trainer module \n",
            "- n_epochs: 10 \n",
            "- loss_func_name: sampled_softmax \n",
            "- loss_func_aggr: mean \n",
            "- device: cuda \n",
            "- optimizing_metric: hit_ratio@10 \n",
            " - checkpoint_dir: experiments/full_train/12252023.153440 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "proto_double_tie_optimal_params = argparse.Namespace(**proto_double_tie_optimal_params)\n",
        "\n",
        "trainer = Trainer(train_loader, val_loader, proto_double_tie_optimal_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "cdc72c5c",
      "metadata": {
        "scrolled": true,
        "id": "cdc72c5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c399487b-929e-4cce-8de9-b2d0d54aa9a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Building FeatureExtractor model ---\n",
            "Built Embedding model \n",
            "- n_objects: 6028 \n",
            "- embedding_dim: 300 \n",
            "- max_norm: None\n",
            "- only_positive: False\n",
            "Built PrototypeEmbedding model \n",
            "- n_prototypes: 80 \n",
            "- use_weight_matrix: False \n",
            "- sim_proto_weight: 0.001 \n",
            "- sim_batch_weight: 0.001 \n",
            "- reg_proto_type: max \n",
            "- reg_batch_type: max \n",
            "- cosine_type: shifted \n",
            "\n",
            "--- Finished building FeatureExtractor model ---\n",
            "\n",
            "--- Building FeatureExtractor model ---\n",
            "Built Embedding model \n",
            "- n_objects: 6028 \n",
            "- embedding_dim: 300 \n",
            "- max_norm: None\n",
            "- only_positive: False\n",
            "Built Embeddingw model \n",
            "- out_dimension: 80 \n",
            "- use_bias: False \n",
            "\n",
            "--- Finished building FeatureExtractor model ---\n",
            "\n",
            "--- Building FeatureExtractor model ---\n",
            "Built Embedding model \n",
            "- n_objects: 3123 \n",
            "- embedding_dim: 300 \n",
            "- max_norm: None\n",
            "- only_positive: False\n",
            "Built PrototypeEmbedding model \n",
            "- n_prototypes: 80 \n",
            "- use_weight_matrix: False \n",
            "- sim_proto_weight: 0.001 \n",
            "- sim_batch_weight: 0.001 \n",
            "- reg_proto_type: max \n",
            "- reg_batch_type: max \n",
            "- cosine_type: shifted \n",
            "\n",
            "--- Finished building FeatureExtractor model ---\n",
            "\n",
            "--- Building FeatureExtractor model ---\n",
            "Built Embedding model \n",
            "- n_objects: 3123 \n",
            "- embedding_dim: 300 \n",
            "- max_norm: None\n",
            "- only_positive: False\n",
            "Built Embeddingw model \n",
            "- out_dimension: 80 \n",
            "- use_bias: False \n",
            "\n",
            "--- Finished building FeatureExtractor model ---\n",
            "\n",
            "Built ConcatenateFeatureExtractors model \n",
            "- model_1: PrototypeEmbedding \n",
            "- model_2: EmbeddingW \n",
            "- invert: False \n",
            "\n",
            "Built ConcatenateFeatureExtractors model \n",
            "- model_1: PrototypeEmbedding \n",
            "- model_2: EmbeddingW \n",
            "- invert: True \n",
            "\n",
            "Built RecSys module \n",
            "- n_users: 6028 \n",
            "- n_items: 3123 \n",
            "- user_feature_extractor: ConcatenateFeatureExtractors \n",
            "- item_feature_extractor: ConcatenateFeatureExtractors \n",
            "- loss_func_name: sampled_softmax \n",
            "- use_bias: False \n",
            "\n",
            "Built Optimizer  \n",
            "- name: adagrad \n",
            "- lr: 0.001 \n",
            "- wd: 0.0001 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Adagrad (\n",
              "Parameter Group 0\n",
              "    differentiable: False\n",
              "    eps: 1e-10\n",
              "    foreach: None\n",
              "    initial_accumulator_value: 0\n",
              "    lr: 0.001\n",
              "    lr_decay: 0\n",
              "    maximize: False\n",
              "    weight_decay: 0.0001\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "trainer._build_model()\n",
        "trainer._build_optimizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "c94980b8",
      "metadata": {
        "scrolled": true,
        "id": "c94980b8"
      },
      "outputs": [],
      "source": [
        "#trainer.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Best model (not see)\n",
        "\n"
      ],
      "metadata": {
        "id": "7WcdJFQlpo9B"
      },
      "id": "7WcdJFQlpo9B"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "9fc0875e",
      "metadata": {
        "id": "9fc0875e"
      },
      "outputs": [],
      "source": [
        "#from natsort import natsorted\n",
        "#path2last_ckpts = os.path.join(\n",
        "#    proto_double_tie_optimal_params.checkpoint_dir,\n",
        "#    natsorted(os.listdir(proto_double_tie_optimal_params.checkpoint_dir))[-1]\n",
        "#)\n",
        "#best_cktp =os.path.join(path2last_ckpts, natsorted(os.listdir(path2last_ckpts))[-1])\n",
        "#print(\"Best checkpoint: \", best_cktp)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from natsort import natsorted\n",
        "path2last_ckpts = os.path.join(\n",
        "    proto_double_tie_optimal_params.checkpoint_dir,\n",
        "    natsorted(os.listdir(proto_double_tie_optimal_params.checkpoint_dir))[0]\n",
        ")\n",
        "best_cktp =os.path.join(path2last_ckpts, natsorted(os.listdir(path2last_ckpts))[-1])\n",
        "print(\"Best checkpoint: \", best_cktp)\n",
        "#Best checkpoint:  experiments/full_train/12242023.150630/best_model_10.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UXdK6FQrRC6",
        "outputId": "7d1ee7ce-6fc9-4a46-bf01-eb990c1d948e"
      },
      "id": "4UXdK6FQrRC6",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best checkpoint:  experiments/full_train/12242023.150630/best_model_10.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "7e9e85ec",
      "metadata": {
        "id": "7e9e85ec"
      },
      "outputs": [],
      "source": [
        "def build_model(trainer):\n",
        "        n_users = trainer.train_loader.dataset.n_users\n",
        "        n_items = trainer.train_loader.dataset.n_items\n",
        "        user_feature_extractor, item_feature_extractor = \\\n",
        "            FeatureExtractorFactory.create_models(trainer.ft_ext_param, n_users, n_items)\n",
        "        # Step 2 --- Building RecSys Module\n",
        "        rec_sys = RecSys(n_users, n_items, trainer.rec_sys_param, user_feature_extractor, item_feature_extractor,\n",
        "                         trainer.loss_func_name, trainer.loss_func_aggr)\n",
        "\n",
        "        rec_sys.init_parameters()\n",
        "\n",
        "        rec_sys = nn.DataParallel(rec_sys)\n",
        "\n",
        "        return rec_sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "c0f19bb0",
      "metadata": {
        "id": "c0f19bb0"
      },
      "outputs": [],
      "source": [
        "#for key, _ in model_up.named_parameters():\n",
        "#    print(key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "96be64cd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96be64cd",
        "outputId": "36f8e8ff-1bb5-4833-e29b-80a3403b6715"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Building FeatureExtractor model ---\n",
            "Built Embedding model \n",
            "- n_objects: 6028 \n",
            "- embedding_dim: 300 \n",
            "- max_norm: None\n",
            "- only_positive: False\n",
            "Built PrototypeEmbedding model \n",
            "- n_prototypes: 80 \n",
            "- use_weight_matrix: False \n",
            "- sim_proto_weight: 0.001 \n",
            "- sim_batch_weight: 0.001 \n",
            "- reg_proto_type: max \n",
            "- reg_batch_type: max \n",
            "- cosine_type: shifted \n",
            "\n",
            "--- Finished building FeatureExtractor model ---\n",
            "\n",
            "--- Building FeatureExtractor model ---\n",
            "Built Embedding model \n",
            "- n_objects: 6028 \n",
            "- embedding_dim: 300 \n",
            "- max_norm: None\n",
            "- only_positive: False\n",
            "Built Embeddingw model \n",
            "- out_dimension: 80 \n",
            "- use_bias: False \n",
            "\n",
            "--- Finished building FeatureExtractor model ---\n",
            "\n",
            "--- Building FeatureExtractor model ---\n",
            "Built Embedding model \n",
            "- n_objects: 3123 \n",
            "- embedding_dim: 300 \n",
            "- max_norm: None\n",
            "- only_positive: False\n",
            "Built PrototypeEmbedding model \n",
            "- n_prototypes: 80 \n",
            "- use_weight_matrix: False \n",
            "- sim_proto_weight: 0.001 \n",
            "- sim_batch_weight: 0.001 \n",
            "- reg_proto_type: max \n",
            "- reg_batch_type: max \n",
            "- cosine_type: shifted \n",
            "\n",
            "--- Finished building FeatureExtractor model ---\n",
            "\n",
            "--- Building FeatureExtractor model ---\n",
            "Built Embedding model \n",
            "- n_objects: 3123 \n",
            "- embedding_dim: 300 \n",
            "- max_norm: None\n",
            "- only_positive: False\n",
            "Built Embeddingw model \n",
            "- out_dimension: 80 \n",
            "- use_bias: False \n",
            "\n",
            "--- Finished building FeatureExtractor model ---\n",
            "\n",
            "Built ConcatenateFeatureExtractors model \n",
            "- model_1: PrototypeEmbedding \n",
            "- model_2: EmbeddingW \n",
            "- invert: False \n",
            "\n",
            "Built ConcatenateFeatureExtractors model \n",
            "- model_1: PrototypeEmbedding \n",
            "- model_2: EmbeddingW \n",
            "- invert: True \n",
            "\n",
            "Built RecSys module \n",
            "- n_users: 6028 \n",
            "- n_items: 3123 \n",
            "- user_feature_extractor: ConcatenateFeatureExtractors \n",
            "- item_feature_extractor: ConcatenateFeatureExtractors \n",
            "- loss_func_name: sampled_softmax \n",
            "- use_bias: False \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "model_up = trainer._build_model()\n",
        "\n",
        "#state_dict = torch.load(r'experiments\\12242023.055103\\best_model_9.pth')\n",
        "state_dict = torch.load(best_cktp)\n",
        "model_up.state_dict().keys()\n",
        "new_s = {}\n",
        "for key, value in state_dict.items():\n",
        "    new_s[\"module.\" + key] = value\n",
        "\n",
        "model_state_dict = model_up.state_dict()\n",
        "\n",
        "assert set(list(model_state_dict.keys())) - set(list(new_s.keys())) == set()\n",
        "model_up.eval()\n",
        "model_up.load_state_dict(new_s)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "608d4f75",
      "metadata": {
        "id": "608d4f75"
      },
      "outputs": [],
      "source": [
        "# model_up = torch.load(checkpoint_dir + '/best_model_10.pth')\n",
        "model_up2 = torch.load(best_cktp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "e8ce5c7e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8ce5c7e",
        "outputId": "1e1a5e92-9432-418b-b1b8-f6fb4a5ba4bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([80, 300])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "model_up2['user_feature_extractor.model_2.linear_layer.weight'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "1debe6cd",
      "metadata": {
        "id": "1debe6cd"
      },
      "outputs": [],
      "source": [
        "items_feats = np.array(model_up2['item_feature_extractor.model_2.embedding_layer.weight'].to('cpu'))\n",
        "user_feats = np.array(model_up2['user_feature_extractor.model_2.embedding_layer.weight'].to('cpu'))\n",
        "\n",
        "user_protos = np.array(model_up2['user_feature_extractor.model_1.prototypes'].to('cpu'))\n",
        "user_embeds = np.array(model_up2['user_feature_extractor.model_1.embedding_ext.embedding_layer.weight'].to('cpu'))\n",
        "item_protos = np.array(model_up2['item_feature_extractor.model_1.prototypes'].to('cpu'))\n",
        "item_embeds = np.array(model_up2['item_feature_extractor.model_1.embedding_ext.embedding_layer.weight'].to('cpu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "c632aef1",
      "metadata": {
        "id": "c632aef1"
      },
      "outputs": [],
      "source": [
        "test_df = pd.read_csv(Path(\"./ProtoMF/data/full_train/listening_history_test.csv\"))\n",
        "test_users  = sorted(test_df.user_id.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "ac613a1c",
      "metadata": {
        "id": "ac613a1c"
      },
      "outputs": [],
      "source": [
        "total_items = pd.read_csv(Path(\"./ProtoMF/data/full_train/item_ids.csv\")).shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "eb26e9aa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb26e9aa",
        "outputId": "48de83dd-9a10-48ad-875b-17a834e0e126"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 1]), torch.Size([1, 3123]))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "torch.tensor([[35]]).shape, torch.arange(total_items).unsqueeze(0).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "4c7c1767",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c7c1767",
        "outputId": "95c56db7-af4b-43ae-f0d5-8732591c99ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "#model_up = model_up.cpu()\n",
        "for param in model_up.parameters():\n",
        "    print(param.device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.as_tensor(test_users).cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkkLoVL1xv4s",
        "outputId": "f2e87139-be62-4e21-dc7a-b997f481a9b0"
      },
      "id": "ZkkLoVL1xv4s",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  35,   58,   64,  101,  103,  126,  130,  133,  145,  148,  149,  156,\n",
              "         159,  163,  168,  172,  182,  183,  187,  191,  192,  194,  200,  228,\n",
              "         230,  234,  236,  238,  270,  284,  292,  301,  305,  309,  313,  318,\n",
              "         328,  337,  342,  349,  353,  396,  401,  406,  409,  410,  417,  420,\n",
              "         422,  436,  440,  452,  460,  480,  494,  516,  526,  529,  547,  621,\n",
              "         622,  631,  639,  646,  665,  676,  689,  690,  694,  696,  708,  725,\n",
              "         734,  735,  741,  747,  750,  751,  765,  789,  793,  827,  837,  838,\n",
              "         844,  870,  879,  882,  909,  911,  928,  935,  951, 1008, 1013, 1017,\n",
              "        1018, 1049, 1059, 1061, 1065, 1086, 1099, 1111, 1115, 1118, 1119, 1123,\n",
              "        1139, 1140, 1147, 1161, 1162, 1178, 1179, 1183, 1191, 1199, 1200, 1208,\n",
              "        1216, 1240, 1243, 1249, 1253, 1257, 1262, 1270, 1274, 1287, 1297, 1299,\n",
              "        1302, 1313, 1325, 1336, 1344, 1348, 1351, 1365, 1385, 1386, 1391, 1395,\n",
              "        1409, 1411, 1417, 1418, 1421, 1422, 1443, 1447, 1487, 1496, 1501, 1520,\n",
              "        1526, 1542, 1543, 1547, 1552, 1556, 1557, 1575, 1583, 1589, 1593, 1595,\n",
              "        1601, 1607, 1620, 1639, 1641, 1643, 1651, 1667, 1694, 1706, 1708, 1713,\n",
              "        1729, 1735, 1744, 1751, 1772, 1774, 1776, 1808, 1830, 1833, 1847, 1850,\n",
              "        1861, 1893, 1908, 1921, 1937, 1939, 1942, 1950, 1954, 1965, 1974, 1976,\n",
              "        1978, 1994, 2008, 2011, 2014, 2018, 2019, 2027, 2037, 2043, 2056, 2059,\n",
              "        2067, 2072, 2073, 2088, 2102, 2107, 2110, 2115, 2118, 2149, 2164, 2168,\n",
              "        2172, 2184, 2186, 2191, 2206, 2221, 2228, 2235, 2238, 2242, 2243, 2266,\n",
              "        2267, 2268, 2312, 2338, 2349, 2355, 2358, 2372, 2376, 2386, 2391, 2403,\n",
              "        2432, 2447, 2449, 2458, 2481, 2485, 2500, 2540, 2590, 2617, 2623, 2637,\n",
              "        2639, 2644, 2651, 2684, 2752, 2756, 2762, 2775, 2777, 2792, 2798, 2806,\n",
              "        2810, 2816, 2820, 2828, 2837, 2843, 2855, 2856, 2864, 2868, 2874, 2883,\n",
              "        2892, 2894, 2899, 2901, 2913, 2939, 2958, 2963, 2979, 2996, 3005, 3006,\n",
              "        3007, 3008, 3011, 3014, 3023, 3032, 3035, 3045, 3047, 3048, 3049, 3074,\n",
              "        3081, 3087, 3100, 3107, 3119, 3122, 3134, 3140, 3144, 3146, 3152, 3153,\n",
              "        3166, 3176, 3197, 3213, 3218, 3223, 3253, 3254, 3256, 3279, 3295, 3306,\n",
              "        3326, 3353, 3357, 3362, 3365, 3385, 3404, 3405, 3406, 3407, 3417, 3427,\n",
              "        3430, 3446, 3448, 3456, 3465, 3467, 3469, 3477, 3497, 3498, 3503, 3506,\n",
              "        3512, 3513, 3514, 3525, 3544, 3556, 3583, 3584, 3586, 3613, 3619, 3641,\n",
              "        3645, 3674, 3681, 3684, 3686, 3688, 3694, 3710, 3725, 3739, 3766, 3785,\n",
              "        3800, 3814, 3817, 3825, 3827, 3833, 3835, 3859, 3933, 3946, 3956, 3963,\n",
              "        3964, 3975, 3978, 3985, 3988, 3998, 4035, 4051, 4078, 4082, 4110, 4119,\n",
              "        4162, 4179, 4225, 4251, 4270, 4287, 4294, 4297, 4302, 4304, 4320, 4347,\n",
              "        4375, 4378, 4409, 4423, 4439, 4454, 4467, 4468, 4478, 4506, 4509, 4532,\n",
              "        4545, 4568, 4571, 4580, 4589, 4596, 4613, 4623, 4626, 4627, 4628, 4635,\n",
              "        4644, 4685, 4716, 4732, 4736, 4751, 4753, 4759, 4762, 4773, 4779, 4790,\n",
              "        4801, 4804, 4811, 4817, 4819, 4822, 4830, 4849, 4855, 4856, 4921, 4922,\n",
              "        4928, 4938, 4946, 4948, 4989, 4999, 5007, 5034, 5037, 5042, 5051, 5075,\n",
              "        5078, 5085, 5088, 5120, 5144, 5160, 5169, 5186, 5193, 5210, 5230, 5238,\n",
              "        5253, 5265, 5269, 5288, 5290, 5300, 5307, 5310, 5317, 5319, 5321, 5343,\n",
              "        5347, 5370, 5375, 5382, 5385, 5400, 5401, 5412, 5425, 5436, 5438, 5441,\n",
              "        5446, 5458, 5461, 5472, 5476, 5508, 5527, 5531, 5545, 5568, 5586, 5609,\n",
              "        5618, 5623, 5624, 5638, 5642, 5645, 5670, 5677, 5711, 5721, 5775, 5800,\n",
              "        5813, 5819, 5825, 5829, 5859, 5861, 5865, 5879, 5910, 5935, 5936, 5937,\n",
              "        5943, 5978, 5983, 5989], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.arange(total_items).unsqueeze(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTaNHorHx1jc",
        "outputId": "b377a846-d01e-4742-e65c-cb47bc89ba96"
      },
      "id": "cTaNHorHx1jc",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   0,    1,    2,  ..., 3120, 3121, 3122]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "cb2d33ec",
      "metadata": {
        "id": "cb2d33ec"
      },
      "outputs": [],
      "source": [
        "test_scores = model_up(torch.as_tensor(test_users).cuda(), torch.arange(total_items).unsqueeze(0).cuda())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.arange(total_items).unsqueeze(0).cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GWNZRRMf_9E",
        "outputId": "082059a1-4c5e-4af6-95ee-89a13109cb76"
      },
      "id": "5GWNZRRMf_9E",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   0,    1,    2,  ..., 3120, 3121, 3122]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "034974ca",
      "metadata": {
        "id": "034974ca"
      },
      "outputs": [],
      "source": [
        "test_scores = test_scores.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "1dc6c9cc",
      "metadata": {
        "id": "1dc6c9cc"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(Path(\"./ProtoMF/data/full_train/listening_history_train.csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "13260a54",
      "metadata": {
        "id": "13260a54"
      },
      "outputs": [],
      "source": [
        "trainset_description = dict(\n",
        "        users = 'user_id',\n",
        "        items = 'item_id'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "c9adf704",
      "metadata": {
        "id": "c9adf704"
      },
      "outputs": [],
      "source": [
        "from utils.evaluation import downvote_seen_items\n",
        "\n",
        "downvote_seen_items(test_scores, train_df.query('user_id in @test_users'), trainset_description)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.query('user_id in @test_users')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pikm3-6_gPyh",
        "outputId": "4028b977-917d-43cc-dfc9-4b60ba189c7b"
      },
      "id": "pikm3-6_gPyh",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Unnamed: 0.1  Unnamed: 0  user_id  item_id  rating  timestamp\n",
              "2773            2773        5016       35     2365       5  978061914\n",
              "2774            2774        5017       35      977       5  978064419\n",
              "2775            2775        5019       35     2698       5  978063192\n",
              "2776            2776        5020       35      548       4  978210234\n",
              "2777            2777        5021       35      549       5  978062718\n",
              "...              ...         ...      ...      ...     ...        ...\n",
              "559820         14164      993913     5989     1481       4  993349205\n",
              "559821         14165      993998     5989     1762       4  993349240\n",
              "559822         14166      994022     5989      394       5  993349150\n",
              "559823         14167      994065     5989      118       4  999473641\n",
              "559824         14168      994093     5989      820       4  993349314\n",
              "\n",
              "[103559 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13f88cd5-05e2-40c7-8b8e-49627e5b0346\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2773</th>\n",
              "      <td>2773</td>\n",
              "      <td>5016</td>\n",
              "      <td>35</td>\n",
              "      <td>2365</td>\n",
              "      <td>5</td>\n",
              "      <td>978061914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2774</th>\n",
              "      <td>2774</td>\n",
              "      <td>5017</td>\n",
              "      <td>35</td>\n",
              "      <td>977</td>\n",
              "      <td>5</td>\n",
              "      <td>978064419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2775</th>\n",
              "      <td>2775</td>\n",
              "      <td>5019</td>\n",
              "      <td>35</td>\n",
              "      <td>2698</td>\n",
              "      <td>5</td>\n",
              "      <td>978063192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2776</th>\n",
              "      <td>2776</td>\n",
              "      <td>5020</td>\n",
              "      <td>35</td>\n",
              "      <td>548</td>\n",
              "      <td>4</td>\n",
              "      <td>978210234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2777</th>\n",
              "      <td>2777</td>\n",
              "      <td>5021</td>\n",
              "      <td>35</td>\n",
              "      <td>549</td>\n",
              "      <td>5</td>\n",
              "      <td>978062718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559820</th>\n",
              "      <td>14164</td>\n",
              "      <td>993913</td>\n",
              "      <td>5989</td>\n",
              "      <td>1481</td>\n",
              "      <td>4</td>\n",
              "      <td>993349205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559821</th>\n",
              "      <td>14165</td>\n",
              "      <td>993998</td>\n",
              "      <td>5989</td>\n",
              "      <td>1762</td>\n",
              "      <td>4</td>\n",
              "      <td>993349240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559822</th>\n",
              "      <td>14166</td>\n",
              "      <td>994022</td>\n",
              "      <td>5989</td>\n",
              "      <td>394</td>\n",
              "      <td>5</td>\n",
              "      <td>993349150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559823</th>\n",
              "      <td>14167</td>\n",
              "      <td>994065</td>\n",
              "      <td>5989</td>\n",
              "      <td>118</td>\n",
              "      <td>4</td>\n",
              "      <td>999473641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559824</th>\n",
              "      <td>14168</td>\n",
              "      <td>994093</td>\n",
              "      <td>5989</td>\n",
              "      <td>820</td>\n",
              "      <td>4</td>\n",
              "      <td>993349314</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>103559 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13f88cd5-05e2-40c7-8b8e-49627e5b0346')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-13f88cd5-05e2-40c7-8b8e-49627e5b0346 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-13f88cd5-05e2-40c7-8b8e-49627e5b0346');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e1999330-d037-4aec-bd0f-e0955d6057b2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e1999330-d037-4aec-bd0f-e0955d6057b2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e1999330-d037-4aec-bd0f-e0955d6057b2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "822df1a4",
      "metadata": {
        "id": "822df1a4"
      },
      "outputs": [],
      "source": [
        "from utils.evaluation import topn_recommendations\n",
        "\n",
        "top_20 = topn_recommendations(test_scores, topn=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "c1e5efd9",
      "metadata": {
        "id": "c1e5efd9"
      },
      "outputs": [],
      "source": [
        "def hr_score(top_n_items, real_likes):\n",
        "    mask = (top_n_items[...,None] == real_likes[:,None]).any(2)\n",
        "    return mask.any(axis=1).mean()\n",
        "\n",
        "def mrr_score(top_n_items, real_likes):\n",
        "    idx = np.arange(1, top_n_items.shape[1] + 1)[None, :]\n",
        "    mask = (top_n_items[...,None] == real_likes[:,None]).any(2)\n",
        "    return (mask / idx).max(axis=1).mean()\n",
        "\n",
        "def coverage_score(top_n_items, total_item_count):\n",
        "    return len(np.unique(top_n_items)) * 1.0 / total_item_count\n",
        "\n",
        "def final_evaluation(recs, test, allowed_items=None):\n",
        "    if allowed_items is not None:\n",
        "        test = test.copy()\n",
        "        test.loc[~test['item_id'].isin(allowed_items), 'item_id'] = -1\n",
        "        recs = recs.copy()\n",
        "        recs[~np.isin(recs, allowed_items)] = -2\n",
        "    max_likes = test.groupby('user_id')['item_id'].apply(len).max()\n",
        "    test_likes = test.groupby('user_id')['item_id'].apply(lambda x: list(np.pad(x, (0, max_likes - len(x)), 'constant', constant_values=-1)))\n",
        "    test_likes = np.asarray(list(test_likes))\n",
        "\n",
        "    total_items = len(test.item_id.unique())\n",
        "\n",
        "    hr = hr_score(recs, test_likes)\n",
        "    mrr = mrr_score(recs, test_likes)\n",
        "    cov = coverage_score(recs, total_items)\n",
        "\n",
        "    print(f'HR={hr}, MRR={mrr}, COV={cov}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "56d3766c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56d3766c",
        "outputId": "767b574f-4aaa-4b7b-d44b-25d4186611c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HR=0.5467625899280576, MRR=0.20304620845901442, COV=0.18233743409490333\n"
          ]
        }
      ],
      "source": [
        "final_evaluation(top_20, test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### еще какие-то расчеты метрик (не запускать)"
      ],
      "metadata": {
        "id": "eT18T728xSDQ"
      },
      "id": "eT18T728xSDQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f23f9a81",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "f23f9a81",
        "outputId": "3333922a-39a6-424e-a7d6-505581ae08ce"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "UndefinedVariableError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/computation/scope.py\u001b[0m in \u001b[0;36mresolve\u001b[0;34m(self, key, is_local)\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_resolvers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolvers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/collections/__init__.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    985\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__missing__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m            \u001b[0;31m# support subclasses that define __missing__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/collections/__init__.py\u001b[0m in \u001b[0;36m__missing__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    977\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__missing__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'itemid'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/computation/scope.py\u001b[0m in \u001b[0;36mresolve\u001b[0;34m(self, key, is_local)\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0;31m# e.g., df[df > 0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'itemid'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mUndefinedVariableError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-11e392a75a7b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mall_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'itemid in @test_items'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'itemid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msub_10_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'itemid in @test_items'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'itemid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'userid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mitems_quant_10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msub_50_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'itemid in @test_items'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'itemid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'userid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mitems_quant_50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   4472\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"level\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"level\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4473\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4474\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4476\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   4610\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"resolvers\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resolvers\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresolvers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4612\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4614\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/computation/eval.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(expr, parser, engine, truediv, local_dict, global_dict, resolvers, level, target, inplace)\u001b[0m\n\u001b[1;32m    351\u001b[0m         )\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0mparsed_expr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;31m# construct the engine and evaluate the parsed expression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expr.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, expr, engine, parser, env, level)\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_visitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPARSERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expr.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    830\u001b[0m         \u001b[0mParse\u001b[0m \u001b[0man\u001b[0m \u001b[0mexpression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         \"\"\"\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_visitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expr.py\u001b[0m in \u001b[0;36mvisit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"visit_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mvisitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvisitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvisit_Module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expr.py\u001b[0m in \u001b[0;36mvisit_Module\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mSyntaxError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"only a single expression is allowed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mexpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvisit_Expr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expr.py\u001b[0m in \u001b[0;36mvisit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"visit_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mvisitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvisitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvisit_Module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expr.py\u001b[0m in \u001b[0;36mvisit_Expr\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvisit_Expr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_rewrite_membership_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expr.py\u001b[0m in \u001b[0;36mvisit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"visit_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mvisitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvisitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvisit_Module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expr.py\u001b[0m in \u001b[0;36mvisit_Compare\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate_In\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0mbinop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBinOp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;31m# recursive case: we have a chained comparison, a CMP b CMP c, etc.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expr.py\u001b[0m in \u001b[0;36mvisit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"visit_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mvisitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvisitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvisit_Module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expr.py\u001b[0m in \u001b[0;36mvisit_BinOp\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvisit_BinOp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m         \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_transform_eq_ne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_downcast_constants\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_evaluate_binop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expr.py\u001b[0m in \u001b[0;36m_maybe_transform_eq_ne\u001b[0;34m(self, node, left, right)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_transform_eq_ne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mleft\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m             \u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"left\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mright\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"right\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expr.py\u001b[0m in \u001b[0;36mvisit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"visit_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mvisitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvisitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvisit_Module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/computation/expr.py\u001b[0m in \u001b[0;36mvisit_Name\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvisit_Name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterm_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvisit_NameConstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTerm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/computation/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, env, side, encoding)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_local\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOCAL_TAG\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDEFAULT_GLOBALS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/computation/ops.py\u001b[0m in \u001b[0;36m_resolve_name\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mis_local\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_local\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_local\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/computation/scope.py\u001b[0m in \u001b[0;36mresolve\u001b[0;34m(self, key, is_local)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mUndefinedVariableError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_local\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mswapkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_key\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_key\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUndefinedVariableError\u001b[0m: name 'itemid' is not defined"
          ]
        }
      ],
      "source": [
        "all_items = train.query('itemid in @test_items')['itemid'].unique()\n",
        "\n",
        "sub_10_items = all_items[train.query('itemid in @test_items').groupby('itemid')['userid'].count() <= items_quant_10]\n",
        "sub_50_items = all_items[train.query('itemid in @test_items').groupby('itemid')['userid'].count() <= items_quant_50]\n",
        "\n",
        "all_users = train.query('userid in @test_users')['userid'].unique()\n",
        "\n",
        "sub_10_users = sorted(all_users[train.query('userid in @test_users').groupby('userid')['itemid'].count() <= users_quant_10])\n",
        "sub_50_users = sorted(all_users[train.query('userid in @test_users').groupby('userid')['itemid'].count() <= users_quant_50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea2b4d49",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea2b4d49",
        "outputId": "7938e689-408b-4f48-f0a3-a8424eb1915c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3123, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ],
      "source": [
        "items_feats.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e36fd2b",
      "metadata": {
        "id": "2e36fd2b"
      },
      "outputs": [],
      "source": [
        "normed_mat_users = np.array(((user_embeds.T) * 1 / np.linalg.norm(user_embeds, 2, axis=1)))\n",
        "normed_mat_protos_user = np.array(((user_protos.T) * (1 / np.linalg.norm(user_protos, 2, axis=1))))\n",
        "user_to_protos = (1 + np.dot(normed_mat_users.T, normed_mat_protos_user))\n",
        "#user_scores = user_to_protos.dot(items_feats.T)\n",
        "\n",
        "normed_mat_items = np.array(((item_embeds.T) * 1 / np.linalg.norm(item_embeds, 2, axis=1)))\n",
        "normed_mat_protos_item = np.array(((item_protos.T) * (1 / np.linalg.norm(item_protos, 2, axis=1))))\n",
        "item_to_protos = (1 + np.dot(normed_mat_items.T, normed_mat_protos_item))\n",
        "#item_scores = item_to_protos.dot(user_feats.T)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "705913a8",
      "metadata": {
        "id": "705913a8"
      },
      "outputs": [],
      "source": [
        "normed_mat_users = np.array(((user_embeds.T) * 1 / np.linalg.norm(user_embeds, 2, axis=1)))\n",
        "normed_mat_protos = np.array(((user_protos.T) * (1 / np.linalg.norm(user_protos, 2, axis=1))))\n",
        "user_to_protos = (1 + np.dot(normed_mat_users.T, normed_mat_protos))\n",
        "scores = user_to_protos.dot(items_feats.T)\n",
        "top_20 = scores.argsort()[:, ::-1][:,:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cb3bc63",
      "metadata": {
        "id": "6cb3bc63",
        "outputId": "ceb82b91-07a3-46ce-d935-80a1fce2ca7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 526,  222,  926, ...,   98,   48,  927],\n",
              "       [ 222,  926, 2257, ..., 2137, 2179,  930],\n",
              "       [ 926,  222, 2257, ...,   98,  944, 1254],\n",
              "       ...,\n",
              "       [ 926, 2257,  928, ..., 2137,  940, 2375],\n",
              "       [2257,  526,  222, ...,  511,    0,  944],\n",
              "       [ 526,  928,  222, ..., 2137,  864,  944]], dtype=int64)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "top_20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cd29443",
      "metadata": {
        "scrolled": true,
        "id": "2cd29443"
      },
      "outputs": [],
      "source": [
        "valid = pd.read_excel(r'C:\\Users\\aleke\\Downloads\\KION_DATASET\\ProtoMF\\data\\ml\\valid_ml_our_split.xlsx')\n",
        "test = pd.read_excel(r'C:\\Users\\aleke\\Downloads\\KION_DATASET\\ProtoMF\\data\\ml\\test_ml_our_split.xlsx')\n",
        "train= pd.read_excel(r'C:\\Users\\aleke\\Downloads\\KION_DATASET\\ProtoMF\\data\\ml\\train_ml_our_split.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53f9cf50",
      "metadata": {
        "id": "53f9cf50"
      },
      "outputs": [],
      "source": [
        "def hr_score(top_n_items, real_likes):\n",
        "    mask = (top_n_items[...,None] == real_likes[:,None]).any(2)\n",
        "    return mask.any(axis=1).mean()\n",
        "\n",
        "def mrr_score(top_n_items, real_likes):\n",
        "    idx = np.arange(1, top_n_items.shape[1] + 1)[None, :]\n",
        "    mask = (top_n_items[...,None] == real_likes[:,None]).any(2)\n",
        "    return (mask / idx).max(axis=1).mean()\n",
        "\n",
        "def coverage_score(top_n_items, total_item_count):\n",
        "    return len(np.unique(top_n_items)) * 1.0 / total_item_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e9ff40a",
      "metadata": {
        "id": "1e9ff40a"
      },
      "outputs": [],
      "source": [
        "max_likes = test.groupby('userid')['itemid'].apply(len).max()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf4b7c4c",
      "metadata": {
        "id": "cf4b7c4c",
        "outputId": "8831d45a-7aa7-4bea-866c-1b833e79d965"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.4154676258992806"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_likes = test.groupby('userid')['itemid'].apply(lambda x: list(np.pad(x, (0, max_likes - len(x)), 'constant', constant_values=-1)))\n",
        "\n",
        "test_users = test_likes.index\n",
        "test_likes = np.asarray(list(test_likes))\n",
        "hr_score(top_20[test_users], np.array(test_likes))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explanation"
      ],
      "metadata": {
        "id": "SPWRyFbTPHYs"
      },
      "id": "SPWRyFbTPHYs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### dataIndex"
      ],
      "metadata": {
        "id": "MWiAhKHVYhkn"
      },
      "id": "MWiAhKHVYhkn"
    },
    {
      "cell_type": "code",
      "source": [
        "from polara import get_movielens_data\n",
        "from dataprep import transform_indices, leave_last_out, verify_time_split, reindex_data, generate_interactions_matrix\n",
        "\n",
        "def take_data_index():\n",
        "    def split_by_time(data, time_q=0.95, timeid='timestamp'):\n",
        "        split_timepoint = data[timeid].quantile(q=time_q, interpolation='nearest')\n",
        "        after = data.query(f'{timeid} >= @split_timepoint')\n",
        "        before = data.drop(after.index)\n",
        "        return before, after\n",
        "\n",
        "    def align_test_by_users(testset, holdout):\n",
        "        test_users = np.intersect1d(holdout['userid'].values, testset['userid'].values)\n",
        "        # only allow the same users to be present in both datasets\n",
        "        testset = testset.query('userid in @test_users').sort_values('userid')\n",
        "        holdout = holdout.query('userid in @test_users').sort_values('userid')\n",
        "        return testset, holdout\n",
        "\n",
        "    def k_core_filtering(data, k=5):\n",
        "        while True:\n",
        "            start_number = len(data)\n",
        "\n",
        "            # Item pass\n",
        "            item_counts = data.itemid.value_counts()\n",
        "            item_above = set(item_counts[item_counts >= 5].index)\n",
        "            data = data[data.itemid.isin(item_above)]\n",
        "            print('Records after item pass: ', len(data))\n",
        "\n",
        "            # User pass\n",
        "            user_counts = data.userid.value_counts()\n",
        "            user_above = set(user_counts[user_counts >= 5].index)\n",
        "            data = data[data.userid.isin(user_above)]\n",
        "            print('Records after user pass: ', len(data))\n",
        "\n",
        "            if len(data) == start_number:\n",
        "                print('Exiting...')\n",
        "                return data\n",
        "\n",
        "    def get_train_test_data_for_validation_movielens(data):\n",
        "        data = data.query('rating >= 3.5')\n",
        "\n",
        "        data = k_core_filtering(data)\n",
        "\n",
        "        train, after = split_by_time(data)\n",
        "        valid, test = split_by_time(after, time_q=0.5)\n",
        "        train_users = train.userid.unique()\n",
        "        train_items = train.itemid.unique()\n",
        "\n",
        "        valid = valid.query('userid in @train_users and itemid in @train_items')\n",
        "        test = test.query('userid in @train_users and itemid in @train_items')\n",
        "\n",
        "        train, data_index = transform_indices(train, 'userid', 'itemid')\n",
        "        valid = reindex_data(valid, data_index)\n",
        "        test = reindex_data(test, data_index)\n",
        "\n",
        "        return train, valid, test, data_index\n",
        "\n",
        "    data = get_movielens_data(include_time=True)\n",
        "    data = data.rename({'movieid': 'itemid'}, axis=1)\n",
        "\n",
        "    train, valid, test, data_index = get_train_test_data_for_validation_movielens(data)\n",
        "    return data_index"
      ],
      "metadata": {
        "id": "qtdhjKg5Vqf4"
      },
      "id": "qtdhjKg5Vqf4",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Main functions"
      ],
      "metadata": {
        "id": "zU8JjcsJYmKm"
      },
      "id": "zU8JjcsJYmKm"
    },
    {
      "cell_type": "code",
      "source": [
        "from rec_sys_folder.explanations_utils import tsne_plot, get_top_k_items, weight_visualization\n",
        "\n",
        "def load_model_trainer_torch(model_path):\n",
        "    model_trainer = trainer._build_model()\n",
        "\n",
        "    state_dict = torch.load(model_path)\n",
        "    model_trainer.state_dict().keys()\n",
        "    new_s = {}\n",
        "    for key, value in state_dict.items():\n",
        "        new_s[\"module.\" + key] = value\n",
        "\n",
        "    model_state_dict = model_trainer.state_dict()\n",
        "\n",
        "    assert set(list(model_state_dict.keys())) - set(list(new_s.keys())) == set()\n",
        "    model_trainer.eval()\n",
        "    model_trainer.load_state_dict(new_s)\n",
        "\n",
        "    model_torch = torch.load(model_path)\n",
        "\n",
        "    return model_trainer, model_torch\n",
        "\n",
        "def get_models_params(model_torch):\n",
        "    items_feats = np.array(model_torch['item_feature_extractor.model_2.embedding_layer.weight'].to('cpu'))\n",
        "    user_feats = np.array(model_torch['user_feature_extractor.model_2.embedding_layer.weight'].to('cpu'))\n",
        "    user_protos = np.array(model_torch['user_feature_extractor.model_1.prototypes'].to('cpu'))\n",
        "    user_embeds = np.array(model_torch['user_feature_extractor.model_1.embedding_ext.embedding_layer.weight'].to('cpu'))\n",
        "    item_protos = np.array(model_torch['item_feature_extractor.model_1.prototypes'].to('cpu'))\n",
        "    item_embeds = np.array(model_torch['item_feature_extractor.model_1.embedding_ext.embedding_layer.weight'].to('cpu'))\n",
        "    item_lin_feats = np.array(model_torch['item_feature_extractor.model_2.linear_layer.weight'].to('cpu'))\n",
        "    user_lin_feats = np.array(model_torch['user_feature_extractor.model_2.linear_layer.weight'].to('cpu'))\n",
        "\n",
        "    return user_feats, user_embeds, user_protos, items_feats, item_embeds, item_protos, item_lin_feats, user_lin_feats"
      ],
      "metadata": {
        "id": "bJ2FranNOc1K"
      },
      "id": "bJ2FranNOc1K",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def movie_data_preparation_for_explanation():\n",
        "    # for work with index. in movie id set new indeces\n",
        "    data_index = take_data_index() # oldindex = data_index[items][newindex] or newindex=np.where(data_index[items]==oldindex)\n",
        "    data_index_items = data_index['items'].to_numpy()\n",
        "    _, movie_df = get_movielens_data(include_time=True, get_genres=True, split_genres=True) # use old index\n",
        "    movie_df = movie_df.query('movieid in @data_index_items')\n",
        "    movie_df['movieid'] = movie_df['movieid'].apply(lambda id: np.where(data_index_items==id)[0].item())\n",
        "    movie_df = movie_df.rename(columns={\"movieid\": \"item_id\"})\n",
        "    movie_df = movie_df.groupby('item_id', as_index=False).agg({'genreid': lambda x: list(x), 'movienm':lambda x: list(x)[0]})\n",
        "\n",
        "    return movie_df, data_index"
      ],
      "metadata": {
        "id": "uZbqVq-YTae7"
      },
      "id": "uZbqVq-YTae7",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from  sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def visualisation(model_path, path_save_fig=None, TSNE=False):\n",
        "    #for futurre saving files\n",
        "    if path_save_fig is None:\n",
        "        model_name = model_path[model_path.rfind('/')+1:]\n",
        "        if not os.path.exists('explanation'): os.mkdir('explanation')\n",
        "        if not os.path.exists(f'explanation/{model_name}'): os.mkdir(f'explanation/{model_name}')\n",
        "        path_save_fig = f'explanation/{model_name}/'\n",
        "\n",
        "    # download model and params\n",
        "    model_trainer, model_torch = load_model_trainer_torch(model_path)\n",
        "    user_feats, user_embeds, user_protos, items_feats, item_embeds, item_protos, item_lin_feats, user_lin_feats = get_models_params(model_torch)\n",
        "\n",
        "    # create tsne representation\n",
        "    if TSNE:\n",
        "        tsne_plot(user_embeds, prototypes=user_protos, object_legend_text='User', perplexity=5,\n",
        "                  path_save_fig = path_save_fig+'tsne_userEmb_prototypes')\n",
        "\n",
        "        tsne_plot(item_embeds, prototypes=user_protos, object_legend_text='Item', perplexity=5,\n",
        "                  path_save_fig = path_save_fig+'tsne_itemEmb_prototypes')\n",
        "\n",
        "    # movie data\n",
        "    movie_df, _ = movie_data_preparation_for_explanation()\n",
        "\n",
        "    # representation of items prototypes\n",
        "    # закидываем просто матрицу симилярити\n",
        "    item_to_protos = cosine_similarity(item_embeds, item_protos) + 1\n",
        "\n",
        "    item_ptotos_interpret = pd.DataFrame()\n",
        "    for p_id in range(item_to_protos.shape[1]):\n",
        "          item_infos_top_k = get_top_k_items(item_weights=item_to_protos, items_info=movie_df, proto_idx=p_id, top_k = 5, invert = False)\n",
        "          item_infos_top_k['proto_id'] = p_id\n",
        "          item_ptotos_interpret = pd.concat((item_ptotos_interpret, item_infos_top_k.reset_index()))\n",
        "    item_ptotos_interpret.to_csv(path_save_fig+'item_ptotos_interpret_topk.csv')\n",
        "\n",
        "    # representation of users prototypes\n",
        "    # делаем что бы юзер соотносился одному прототипу\n",
        "    user_to_protos = np.eye(user_protos.shape[0]) * 2 # [user; userproto]\n",
        "    user_proto_item_scores = user_to_protos.dot(item_lin_feats.dot(item_embeds.T)) # [user_proto; item]\n",
        "\n",
        "    user_ptotos_interpret = pd.DataFrame()\n",
        "    for p_id in range(user_to_protos.shape[1]):\n",
        "          user_infos_top_k = get_top_k_items(item_weights=user_proto_item_scores.T, items_info=movie_df, proto_idx=p_id, top_k = 5, invert = False)\n",
        "          user_infos_top_k['proto_id'] = p_id\n",
        "          user_ptotos_interpret = pd.concat((user_ptotos_interpret, user_infos_top_k.reset_index()))\n",
        "    user_ptotos_interpret.to_csv(path_save_fig+'user_ptotos_interpret_topk.csv')\n",
        "\n",
        "    return item_ptotos_interpret, user_ptotos_interpret"
      ],
      "metadata": {
        "id": "WhZTBFUHudn6"
      },
      "id": "WhZTBFUHudn6",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def take_top_interpret_proto(item_ptotos_interpret, topk=5):\n",
        "    top_proto_ids_max = item_ptotos_interpret.groupby('proto_id').agg({'item weight': 'max'}).sort_values('item weight').index[-topk:]\n",
        "    top_proto_ids_sum = item_ptotos_interpret.groupby('proto_id').agg({'item weight': 'sum'}).sort_values('item weight').index[-topk:]\n",
        "    # разницы нет\n",
        "    return item_ptotos_interpret[item_ptotos_interpret.proto_id.isin(top_proto_ids_max)], item_ptotos_interpret[item_ptotos_interpret.proto_id.isin(top_proto_ids_max)]"
      ],
      "metadata": {
        "id": "Swltfky7xGny"
      },
      "id": "Swltfky7xGny",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def take_scores_by_matrices(model_torch, test_users):\n",
        "    user_feats, user_embeds, user_protos, items_feats, item_embeds, item_protos, item_lin_feats, user_lin_feats = get_models_params(model_torch)\n",
        "    U_score = (1 + cosine_similarity(user_embeds, user_protos)).dot(item_lin_feats.dot(item_embeds.T))\n",
        "    I_score = user_embeds.dot(user_lin_feats.T).dot((1 + cosine_similarity(item_embeds, item_protos)).T)\n",
        "    ALL_score = U_score + I_score\n",
        "    return ALL_score[test_users]"
      ],
      "metadata": {
        "id": "I9Wrf59pSmUM"
      },
      "id": "I9Wrf59pSmUM",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'experiments/full_train/12242023.150630/best_model_10.pth'\n",
        "model_trainer, model_torch = load_model_trainer_torch(model_path)\n",
        "user_feats, user_embeds, user_protos, items_feats, item_embeds, item_protos, item_lin_feats, user_lin_feats = get_models_params(model_torch)"
      ],
      "metadata": {
        "id": "nRvlpmJ20yFo"
      },
      "id": "nRvlpmJ20yFo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'experiments/full_train/12242023.150630/best_model_10.pth'\n",
        "item_interp_df, user_interp_df = visualisation(model_path)"
      ],
      "metadata": {
        "id": "DtEIxem_VvAl"
      },
      "id": "DtEIxem_VvAl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_interp_df[user_interp_df.proto_id==0][['genreid','movienm']].to_numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6ncGbkEyxil",
        "outputId": "7ae2b3f6-c970-4954-94ac-cefb75fce49e"
      },
      "id": "s6ncGbkEyxil",
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[list(['Drama']), 'Verdict, The (1982)'],\n",
              "       [list(['Action', 'Sci-Fi']), 'X-Men (2000)'],\n",
              "       [list(['Comedy']), 'Bull Durham (1988)'],\n",
              "       [list(['Drama', 'Thriller']), 'Frequency (2000)'],\n",
              "       [list(['Drama', 'Mystery']), 'JFK (1991)']], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# берем какой нибудь фильм, какого ни будь пользователя и смотрим какие прототипы повлияют на их коннект\n",
        "user_id = 0\n",
        "item_id = 0\n",
        "u_sim_mtx = 1 + cosine_similarity(user_embeds, user_protos) #[user, user_prot]\n",
        "u_proj = user_embeds.dot(user_lin_feats.T) #[project, users]\n",
        "i_sim_mtx = 1 + cosine_similarity(item_embeds, item_protos) #[item, item_proto]\n",
        "i_proj = item_embeds.dot(item_lin_feats.T) #[proj, items]"
      ],
      "metadata": {
        "id": "b1RNog1iWfy2"
      },
      "id": "b1RNog1iWfy2",
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def weight_visualization(u_sim_mtx: np.ndarray, u_proj: np.ndarray, i_sim_mtx: np.ndarray, i_proj: np.ndarray,\n",
        "                         annotate_top_k: int = 3, item_ptotos_interpret=None, user_ptotos_interpret=None, item_id=None,\n",
        "                         verbose_proto_info=False, path_save_fig=None):\n",
        "    \"\"\"\n",
        "    Creates weight visualization plots which is used to explain the recommendation of ProtoMF\n",
        "    :param u_sim_mtx,...,i_proj: vectors that are obtained by the UI-PROTOMF model given the user and item pair.\n",
        "    :param annotate_top_k: how many of the highest logits need to be annotated\n",
        "    \"\"\"\n",
        "\n",
        "    rescale = lambda y: 1 - ((y + np.max(y)) / (np.max(y) * 2))\n",
        "\n",
        "    def compute_ylims(array):\n",
        "        y_lim_max = np.max(array) * (1 + 1 / 9)\n",
        "        y_lim_min = np.min(array) * (1 + 1 / 9)\n",
        "        return y_lim_min, y_lim_max\n",
        "\n",
        "    # Computing the logits\n",
        "\n",
        "    u_prods = u_sim_mtx * i_proj\n",
        "    i_prods = i_sim_mtx * u_proj\n",
        "\n",
        "    u_dot = u_prods.sum()\n",
        "    i_dot = i_prods.sum()\n",
        "\n",
        "    i_n_prototypes = i_sim_mtx.shape[-1]\n",
        "    u_n_prototypes = u_sim_mtx.shape[-1]\n",
        "\n",
        "    # Rescale the plots according to the number of prototypes\n",
        "    i_vis_ratio = i_n_prototypes / (i_n_prototypes + u_n_prototypes)\n",
        "    u_vis_ratio = 1 - i_vis_ratio\n",
        "\n",
        "    # Compute max and mins of the visualization of the logits\n",
        "    prods_lims = compute_ylims(np.concatenate([u_prods, i_prods]))\n",
        "    proj_lims = compute_ylims(np.concatenate([u_proj, i_proj]))\n",
        "    sim_mtx_lims = (0, compute_ylims(np.concatenate([u_sim_mtx, i_sim_mtx]))[1])\n",
        "\n",
        "    # Plotting the users\n",
        "    u_fig, u_axes = plt.subplots(3, 2, sharey='row', dpi=100, figsize=(20 * u_vis_ratio, 10))\n",
        "    u_x = np.arange(u_n_prototypes)\n",
        "\n",
        "    bars_u_prods = u_axes[0][0].bar(u_x, u_prods, color=plt.get_cmap('coolwarm')(rescale(u_prods)))\n",
        "    bars_i_proj = u_axes[1][0].bar(u_x, i_proj, color=plt.get_cmap('coolwarm')(rescale(i_proj)))\n",
        "    bars_u_sim_mtx = u_axes[2][0].bar(u_x, u_sim_mtx, color=plt.get_cmap('coolwarm')(rescale(u_sim_mtx)))\n",
        "\n",
        "    u_axes[0][0].set_ylim(prods_lims)\n",
        "    u_axes[1][0].set_ylim(proj_lims)\n",
        "    u_axes[2][0].set_ylim(sim_mtx_lims)\n",
        "\n",
        "    u_annotate_protos = np.argsort(-u_prods)[:annotate_top_k]\n",
        "    for idx, bars in enumerate([bars_u_prods, bars_i_proj, bars_u_sim_mtx]):\n",
        "        for u_annotate_idx in u_annotate_protos:\n",
        "            bar = bars[u_annotate_idx]\n",
        "            label_x = bar.get_x() - 0.8\n",
        "            label_y = bar.get_height() + (2e-2 if idx == 2 else 1e-2)\n",
        "            u_axes[idx][0].annotate(f'{u_annotate_idx}', (label_x, label_y), fontsize=11)\n",
        "\n",
        "    u_axes[0][0].set_xlabel(r'$ {\\mathbf{s}}^{\\mathrm{user}}$', fontsize=16)\n",
        "    u_axes[1][0].set_xlabel('$ \\hat{\\mathbf{t}} $', fontsize=16)\n",
        "    u_axes[2][0].set_xlabel('$ \\mathbf{u}^{*} $', fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.plot()\n",
        "\n",
        "    # Plotting the items\n",
        "    #i_fig, i_axes = plt.subplots(3, 1, sharey='row', dpi=100, figsize=(i_vis_ratio * 8, 8))\n",
        "    i_x = np.arange(i_n_prototypes)\n",
        "\n",
        "    bars_i_prods = u_axes[0][1].bar(i_x, i_prods, color=plt.get_cmap('coolwarm')(rescale(i_prods)))\n",
        "    bars_u_proj = u_axes[1][1].bar(i_x, u_proj, color=plt.get_cmap('coolwarm')(rescale(u_proj)))\n",
        "    bars_i_sim_mtx = u_axes[2][1].bar(i_x, i_sim_mtx, color=plt.get_cmap('coolwarm')(rescale(i_sim_mtx)))\n",
        "\n",
        "    u_axes[0][1].set_ylim(prods_lims)\n",
        "    u_axes[1][1].set_ylim(proj_lims)\n",
        "    u_axes[2][1].set_ylim(sim_mtx_lims)\n",
        "\n",
        "    # Annotations\n",
        "    i_annotate_protos = np.argsort(-i_prods)[:annotate_top_k]\n",
        "    for idx, bars in enumerate([bars_i_prods, bars_u_proj, bars_i_sim_mtx]):\n",
        "        for i_annotate_idx in i_annotate_protos:\n",
        "            bar = bars[i_annotate_idx]\n",
        "            label_x = bar.get_x() + (-0.8 if idx == 2 else +0)\n",
        "            label_y = bar.get_height() + (2e-2 if idx == 2 else 1e-2)\n",
        "            u_axes[idx][1].annotate(f'{i_annotate_idx}', (label_x, label_y), fontsize=11)\n",
        "\n",
        "    u_axes[0][1].set_xlabel('$ \\mathbf{s}^{\\mathrm{item}} $', fontsize=16)\n",
        "    u_axes[1][1].set_xlabel('$ \\hat{\\mathbf{u}} $', fontsize=16)\n",
        "    u_axes[2][1].set_xlabel('$ \\mathbf{t}^{*} $', fontsize=16)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.plot()\n",
        "\n",
        "\n",
        "    if item_ptotos_interpret is not None and user_ptotos_interpret is not None and verbose_proto_info==True:\n",
        "        if item_id:\n",
        "          item_data = item_ptotos_interpret[item_ptotos_interpret.item_id==item_id]\n",
        "          print(f'Film {item_id}:{item_data.movienm.item()}, ganre:{item_data.genreid.item()}\\n')\n",
        "        for i in range(annotate_top_k):\n",
        "          text = user_ptotos_interpret[user_ptotos_interpret.proto_id==u_annotate_protos[i]][['genreid','movienm']].to_numpy()\n",
        "          print(f'U-proto {u_annotate_protos[i]}: {text}\\n')\n",
        "        for i in range(annotate_top_k):\n",
        "          text = item_ptotos_interpret[item_ptotos_interpret.proto_id==i_annotate_protos[i]][['genreid','movienm']].to_numpy()\n",
        "          print(f'I-proto {i_annotate_protos[i]}: {text}\\n')\n",
        "\n",
        "    if path_save_fig:\n",
        "        plt.savefig(path_save_fig, format='pdf')\n",
        "\n",
        "weight_visualization(u_sim_mtx=u_sim_mtx[user_id], u_proj=u_proj[user_id], i_sim_mtx=i_sim_mtx[item_id], i_proj=i_proj[item_id],\n",
        "                         annotate_top_k=4, item_ptotos_interpret=item_interp_df,user_ptotos_interpret=user_interp_df, item_id=item_id, verbose_proto_info=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aYEymWZRswgr",
        "outputId": "21c96f71-9690-45d7-c780-2d5fdbe1ca41"
      },
      "id": "aYEymWZRswgr",
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "U-proto 41: [[list(['Animation', \"Children's\", 'Comedy']) 'Toy Story (1995)']\n",
            " [list(['Horror']) 'Exorcist, The (1973)']\n",
            " [list(['Drama']) 'Sid and Nancy (1986)']\n",
            " [list(['Comedy']) 'My Cousin Vinny (1992)']\n",
            " [list(['Action', 'Drama', 'War']) 'Saving Private Ryan (1998)']]\n",
            "\n",
            "U-proto 60: [[list(['Comedy', 'Drama']) 'Where the Heart Is (2000)']\n",
            " [list(['Action', 'Comedy', 'Drama']) 'Get Shorty (1995)']\n",
            " [list(['Drama']) 'All About Eve (1950)']\n",
            " [list(['Action', 'Drama']) 'Gladiator (2000)']\n",
            " [list(['Comedy', 'Romance']) 'Wedding Singer, The (1998)']]\n",
            "\n",
            "U-proto 5: [[list(['Comedy', 'Drama']) 'North Dallas Forty (1979)']\n",
            " [list(['Action', 'Adventure', 'Sci-Fi']) 'Stargate (1994)']\n",
            " [list(['Crime', 'Film-Noir']) 'Asphalt Jungle, The (1950)']\n",
            " [list(['Drama']) 'Wonderland (1999)']\n",
            " [list(['Action', 'Adventure']) 'Good Man in Africa, A (1994)']]\n",
            "\n",
            "U-proto 52: [[list(['Comedy', 'Drama']) 'Do the Right Thing (1989)']\n",
            " [list(['Romance']) 'Persuasion (1995)']\n",
            " [list(['Action', 'Sci-Fi']) 'Godzilla (Gojira) (1984)']\n",
            " [list(['Drama']) 'Secret of Roan Inish, The (1994)']\n",
            " [list(['Drama', 'Mystery']) 'Conversation, The (1974)']]\n",
            "\n",
            "I-proto 35: [[list(['Drama']) 'Karate Kid, The (1984)']\n",
            " [list(['Horror']) 'Urban Legends: Final Cut (2000)']\n",
            " [list(['Comedy', 'Thriller']) 'Zero Effect (1998)']\n",
            " [list(['Drama', 'War']) 'Michael Collins (1996)']\n",
            " [list(['Drama']) \"We're No Angels (1989)\"]]\n",
            "\n",
            "I-proto 39: [[list(['Comedy']) 'Waterboy, The (1998)']\n",
            " [list(['Crime', 'Drama', 'Thriller']) 'Desperate Measures (1998)']\n",
            " [list(['Drama', 'Fantasy'])\n",
            "  'Faraway, So Close (In Weiter Ferne, So Nah!) (1993)']\n",
            " [list(['Comedy', 'Western']) 'Lightning Jack (1994)']\n",
            " [list(['Drama'])\n",
            "  'Ciao, Professore! (Io speriamo che me la cavo ) (1993)']]\n",
            "\n",
            "I-proto 58: [[list(['Drama']) 'Ponette (1996)']\n",
            " [list(['Comedy', 'Romance']) 'Mickey Blue Eyes (1999)']\n",
            " [list(['Action']) 'Steel (1997)']\n",
            " [list(['Action']) 'Kid, The (1921)']\n",
            " [list(['Drama', 'Mystery']) 'Anatomy of a Murder (1959)']]\n",
            "\n",
            "I-proto 9: [[list(['Comedy']) 'Kentucky Fried Movie, The (1977)']\n",
            " [list(['Comedy', 'Thriller']) 'Homegrown (1998)']\n",
            " [list(['Thriller']) 'Deterrence (1998)']\n",
            " [list(['Comedy']) 'Pajama Party (1964)']\n",
            " [list(['Comedy', 'Drama', 'Romance']) 'Next Stop, Wonderland (1998)']]\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N8qYjG7j3o4k"
      },
      "id": "N8qYjG7j3o4k",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ZZtpylKjoW1c",
        "nYyIcEKZpMs7",
        "s9YrJEzMpjlf",
        "7WcdJFQlpo9B",
        "eT18T728xSDQ",
        "MWiAhKHVYhkn"
      ],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}